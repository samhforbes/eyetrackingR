[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 eyetrackingR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/divergence_vignette.html","id":"overview-of-this-vignette","dir":"Articles","previous_headings":"","what":"Overview of this vignette","title":"Estimating time windows of divergence","text":"vignette, want ascertain predictor significant effect trial. Analyses aggregate trial window tell us whether effect significant, growth curve analyses tell us trajectory effect course trial, onset-contingent analyses can tell reaction times certain experimental designs. none approaches allow ask: onset predictor’s effect, long effect last? eyetrackingR includes two types analyses answering questions, cover .","code":""},{"path":"/articles/divergence_vignette.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Estimating time windows of divergence","text":"performing analysis, ’ll need prepare clean dataset. quickly notes , information, see vignette preparing data. begin, need use make_time_sequence_data generate time-binned dataframe. ’ll summarize subjects now.","code":"set.seed(42)  library(\"Matrix\") library(\"lme4\") library(\"ggplot2\") library(\"eyetrackingR\") ## Loading required package: dplyr ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                         participant_column = \"ParticipantName\",                        trial_column = \"Trial\",                        time_column = \"TimeFromTrialOnset\",                        trackloss_column = \"TrackLoss\",                        aoi_columns = c('Animate','Inanimate'),                        treat_non_aoi_looks_as_missing = TRUE                 )  # subset to response window post word-onset response_window <- subset_by_window(data,                                      window_start_time = 15500,                                      window_end_time = 21000,                                      rezero = FALSE) ## Avg. window length in new data will be 5500 # analyze amount of trackloss by subjects and trials (trackloss <- trackloss_analysis(data = response_window))  # remove trials with > 25% of trackloss response_window_clean <- clean_by_trackloss(data = response_window,                                             trial_prop_thresh = .25) ## Performing Trackloss Analysis... ## Will exclude trials whose trackloss proportion is greater than : 0.25 ##  ...removed  33  trials. # create Target condition column response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial),                                         yes = 'Inanimate',                                         no  = 'Animate') ) response_time <- make_time_sequence_data(response_window_clean,                                   time_bin_size = 100,                                    predictor_columns = c(\"Target\"),                                   aois = \"Animate\",                                   summarize_by = \"ParticipantName\" )  # visualize timecourse plot(response_time, predictor_column = \"Target\") +    theme_light() +   coord_cartesian(ylim = c(0,1))"},{"path":"/articles/divergence_vignette.html","id":"testing-time-bins-independently","dir":"Articles","previous_headings":"","what":"Testing Time-Bins Independently","title":"Estimating time windows of divergence","text":"One straightforward method testing divergences simply perform statistical test time-bin separately. method problematic, walking explaining help set methods. EyetrackingR provides analyze_time_bins, function makes sequential tests like easy implement.  method suggests looking diverges across conditions early 16100. However, method control family-wise error rate–, probability finding least one divergence across conditions none actually exists. performing many tests, bound get statistically significant results, even effect actually present. real effect, test completely independent, alpha test .05, odds least one false alarm … …almost 95%! course, two assumptions described aren’t met: independence assumption isn’t met (clearly given time-bin similar neighboring time-bins), “real effect” assumption probably isn’t met (given analyses vignettes). still need control family-wise error rate. One approach bonferroni correction. simply lower alpha according number time-bins, family-wise error rate goes back : apply correction using p_adjust_method:  method seems overly conservative, indeed : correction assumes ‘worst case scenario’ time-bins fully independent– mentioned, clearly case. methods less stringent. method available R’s p.adjust function available analyze_time_bins. See documentation function details. mentioned , isn’t really good reason use Bonferroni method, Holm’s method controls family-wise error just well, sometimes powerful:","code":"tb_analysis <- analyze_time_bins(data = response_time, predictor_column = \"Target\", test = \"t.test\", alpha = .05) ## Computing t.test for each time bin... plot(tb_analysis, type = \"estimate\") + theme_light() summary(tb_analysis) ## Test Type:    t.test  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Runs of Significant Time Bins:  ## Positive Run 1  =====  ##  Time:        16100 - 19300  ## Positive Run 2  =====  ##  Time:        19400 - 21000 alpha <- .05 num_time_bins <- nrow(tb_analysis) (prob_no_false_alarm_per_bin <- 1-alpha) ## [1] 0.95 (prob_no_false_alarm_any_bin <- prob_no_false_alarm_per_bin^num_time_bins) ## [1] 0.05953856 (prob_at_least_one_false_alarm <- 1-prob_no_false_alarm_any_bin) ## [1] 0.9404614 alpha <- .05 / num_time_bins (prob_no_false_alarm_per_bin <- 1-alpha) ## [1] 0.9990909 (prob_no_false_alarm_any_bin <- prob_no_false_alarm_per_bin^num_time_bins) ## [1] 0.9512078 (prob_at_least_one_false_alarm <- 1-prob_no_false_alarm_any_bin) ## [1] 0.04879221 tb_analysis_bonf <- analyze_time_bins(data = response_time, predictor_column = \"Target\", test = \"t.test\", alpha = .05,                                  p_adjust_method = \"bonferroni\") ## Computing t.test for each time bin... plot(tb_analysis_bonf) + theme_light() summary(tb_analysis_bonf) ## Test Type:    t.test  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Runs of Significant Time Bins:  ## Positive Run 1  =====  ##  Time:        16300 - 17800  ## Positive Run 2  =====  ##  Time:        18100 - 18500  ## Positive Run 3  =====  ##  Time:        20600 - 20800 tb_analysis_holm <- analyze_time_bins(data = response_time, predictor_column = \"Target\", test = \"t.test\", alpha = .05,                                  p_adjust_method = \"holm\") ## Computing t.test for each time bin... plot(tb_analysis_holm) + theme_light() summary(tb_analysis_holm) ## Test Type:    t.test  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Runs of Significant Time Bins:  ## Positive Run 1  =====  ##  Time:        16300 - 18500  ## Positive Run 2  =====  ##  Time:        20600 - 20800"},{"path":"/articles/divergence_vignette.html","id":"bootstrapped-smoothed-divergence-analysis","dir":"Articles","previous_headings":"","what":"Bootstrapped smoothed divergence analysis","title":"Estimating time windows of divergence","text":"One concern multiple-testing using corrections severely limits power: controlling family-wise error rate, sacrifice ability detect effects present. fact, even uncorrected, overly liberal test seems made small error conservative direction: split runs statistically significant time-bins two, due small downward blip one time-bins. seems unlikely effect actually vanished single time bin: instead, seems likely eye-tracking data noisy, try ignore small variations result noise. One approach perform statistical test operates smoothed version data (similar Wendt et al., 2014). involves: Resampling replacement data (e.g., randomly resampling subjects condition). resample, fitting smoothing curve data (choosing either smooth.spline(), loess(), smoother) Repeating steps (1) (2) thousands times generate distribution, Obtain 95% confidence intervals distribution. time-bins whose confidence intervals overlap zero can considered statistically significant alpha = .05. useful technique estimating timepoints divergence two conditions, smoothing helps remove minor deviations might disrupt otherwise considered single divergent period. can especially helpful infant data, can extremely noisy. Note approach can deal testing differences across two levels predictor (e.g., experimental manipulation, continous covariate). method returns list divergences two conditions based time windows (default) 95% confidence intervals include 0 (.e., p < .05).  can see method (probably correctly) identified trial involves single divergence looking across conditions, rather two divergences separated single time-bin. However, important note method doesn’t explicitly control family-wise error rate. unfortunately, test doesn’t produce p-value bin, can perform (manual) Bonferroni-correction.  correcting, test suffers many problems Bonferroni t-tests.","code":"tb_bootstrap <- analyze_time_bins(response_time, predictor_column = 'Target', test= 'boot_splines',                                    within_subj = TRUE, bs_samples = 1000, alpha = .05) plot(tb_bootstrap) + theme_light() summary(tb_bootstrap) ## Test Type:    boot_splines  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Runs of Significant Time Bins:  ## Positive Run 1  =====  ##  Time:        15900 - 21000 tb_bootstrap_bonf <- analyze_time_bins(response_time, predictor_column = 'Target', test= 'boot_splines',                                    within_subj = TRUE, alpha = .05/num_time_bins) plot(tb_bootstrap_bonf) + theme_light() summary(tb_bootstrap_bonf) ## Test Type:    boot_splines  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Runs of Significant Time Bins:  ## Positive Run 1  =====  ##  Time:        16100 - 18900  ## Positive Run 2  =====  ##  Time:        19600 - 20600"},{"path":"/articles/divergence_vignette.html","id":"bootstrapped-cluster-based-permutation-analysis","dir":"Articles","previous_headings":"","what":"Bootstrapped cluster-based permutation analysis","title":"Estimating time windows of divergence","text":"saw problems false-alarms sensitivity. zero-sum game. One approach offers excellent compromise two referred cluster-based permutation analysis (Maris & Oostenveld, 2007). procedure involves two main steps. First, run test time bin quantifies statistical significance effect time bin. acts “first pass,” group together clusters adjacent bins get first pass. shuffle data, performing test--cluster iteration shuffled data. shuffled data tells us kinds clusters expect effect (.e., randomly scrambled data). detail, eyetrackingR : Run statistical test time-bin data. can valid appropriate statistic quantifies probability data null hypothesis: t-test, wilcox.test, linear models, etc.– whatever appropriate data. Take time-bins whose test passed threshold statistic (e.g., t > 2), group adjacency. call time-clusters. time-cluster, calculate sum statistics time-bins inside . Take data randomly shuffle . Perform (1)-(3) shuffled dataset. Save biggest sum-statistic. Repeat steps (4) (5) hundreds times. lead distribution summed-statistics, representing results statistical test shuffled data. Intuitively, distribution represents kind sum-statistics expect get chance, effect present (.e., data just randomly shuffled). Compare cluster-statistics step (3) distribution found (6) obtain p-value. , example, get distribution sum-statistics, 6.4% sum-statistics distribution extreme sum-statistic cluster, p-value cluster p = .064. analysis two main advantages ones reviewed far: naturally controls false-alarm rate sacrificing little sensitivity. implementation eyetrackingR allows use method variety statistical techniques (t.test, wilcox.test, (g)lm, (g)lmer), continuous predictors, covariates, etc. can also included model tested. even provide (experimental) support using boot-splines test performed time bin. perform analysis, first need set threshold “first pass,” time-bins included clusters. can source misconceptions. size initial threshold set set principled way (e.g., don’t run cluster analysis, examine result, decide want use different threshold). perhaps surprisingly, test controls family-wise error rate, even don’t choose threshold corresponds p = .05. threshold affects first pass shuffled data: let time-bins intial clusters, time-bins let shuffled data well, bigger time-clusters expected null distribution. , ’ll just set threshold based t-distribution: ~2.06 corresponds usual statistic use t-test sample. can look initial clusters:  tells us two potential clusters. described procedure , eyetrackingR next bootstraps “null” distribution, can visualized:  can interpret results? probabilities listed tell us probability seeing effect cluster (bigger) null-hypothesis true. course, probabilities aren’t accurate unless run enough iterations get fuller simulation whole null distribution (’ve just ommitted purposes speed). Note actually ended getting virtually identical results initial analysis sequential time-bins! ’s effect quite large; didn’t worry spuriously significant time-bins probably weren’t . Let’s run quick analysis better job showing virtues cluster analysis. ’ll examine hypothesis infants higher MCDI vocabulary scores baseline bias look animate object. Note different hypothesis high-vocab infants likely look trial target; instead examining unlikely hypothesis high-vocab infants baseline preference. analysis good showing virtues cluster analysis two reasons. First, effect unlikely real, (see ) sequential independent tests time-bin give false-alarms. Second, effect can’t assessed analyses allow testing two-level factors (like t-tests), predictor continuous. EyetrackingR allows us accomplish quite easily using lm test instead t-test.  used uncorrected sequential test method, get appears statistically significant preference animate object among high-vocab children early trial. trust real effect?  Cluster-analysis (probably correctly) says : expect get divergence least large ~%25 time null-hypothesis.","code":"num_sub = length(unique((response_window_clean$ParticipantName))) threshold_t = qt(p = 1 - .05/2,                   df = num_sub-1) # pick threshold t based on alpha = .05 two tailed df_timeclust <- make_time_cluster_data(response_time,                                        test= \"t.test\", paired=TRUE,                                       predictor_column = \"Target\",                                        threshold = threshold_t)  plot(df_timeclust) +  ylab(\"T-Statistic\") + theme_light() summary(df_timeclust) ## Test Type:    t.test  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Summary of Clusters ====== ##   Cluster Direction SumStatistic StartTime EndTime ## 1       1  Positive    132.29900     16100   19300 ## 2       2  Positive     42.31067     19400   20800 clust_analysis <- analyze_time_clusters(df_timeclust, within_subj=TRUE, paired=TRUE,quiet = TRUE,                                         samples=150) # in practice, you should use a lot more plot(clust_analysis) + theme_light() summary(clust_analysis) ## Test Type:    t.test  ## Predictor:    Target  ## Formula:  Prop ~ Target  ## Null Distribution   ======  ##  Mean:        0.5894  ##  2.5%:        -21.7784  ## 97.5%:        24.6837  ## Summary of Clusters ====== ##   Cluster Direction SumStatistic StartTime EndTime Probability ## 1       1  Positive    132.29900     16100   19300 0.000000000 ## 2       2  Positive     42.31067     19400   20800 0.006666667 response_time_between <- make_time_sequence_data(response_window_clean,                                   time_bin_size = 100,                                    predictor_columns = c(\"Sex\", \"MCDI_Total\"),                                   aois = \"Animate\",                                   summarize_by = \"ParticipantName\" )  df_timeclust_between <- make_time_cluster_data(response_time_between,                                        test= \"lm\",                                       predictor_column = \"MCDI_Total\",                                        threshold = threshold_t)  plot(df_timeclust_between) +  ylab(\"T-Statistic\") + theme_light() summary(df_timeclust_between) ## Test Type:    lm  ## Predictor:    MCDI_Total  ## Formula:  Prop ~ MCDI_Total  ## Summary of Clusters ====== ##   Cluster Direction SumStatistic StartTime EndTime ## 1       1  Negative    -6.766357     16100   16400 set.seed(5) clust_analysis_between <- analyze_time_clusters(df_timeclust_between, within_subj = FALSE, quiet = TRUE,                                         samples=150) # in practice, you should use a lot more plot(clust_analysis_between) + theme_light() summary(clust_analysis_between) ## Test Type:    lm  ## Predictor:    MCDI_Total  ## Formula:  Prop ~ MCDI_Total  ## Null Distribution   ======  ##  Mean:        -0.2957  ##  2.5%:        -23.0358  ## 97.5%:        23.4564  ## Summary of Clusters ====== ##   Cluster Direction SumStatistic StartTime EndTime Probability ## 1       1  Negative    -6.766357     16100   16400   0.2933333"},{"path":"/articles/divergence_vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating time windows of divergence","text":"Maris, E., Oostenveld, R., (2007). Nonparametric statistical testing EEG- MEG-data. Journal Neuroscience Methods 164 (1), 177–190. Wendt, D., Brand, T., & Kollmeier, B. (2014). Eye-Tracking Paradigm Analyzing Processing Time Sentences Different Linguistic Complexities. PLoS ONE, 9(6), e100186. https://doi.org/10.1371/journal.pone.0100186.t003","code":""},{"path":"/articles/growth_curve_analysis_vignette.html","id":"overview-of-this-vignette","dir":"Articles","previous_headings":"","what":"Overview of this vignette","title":"Performing a growth curve analysis using eyetrackingR","text":"vignette, want examine data without throwing time predictor. , want ask differences () Target conditions emerged time trial. , perform growth curve analysis.","code":""},{"path":"/articles/growth_curve_analysis_vignette.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Performing a growth curve analysis using eyetrackingR","text":"performing analysis, ’ll need prepare clean dataset. quickly notes , information, see vignette preparing data.","code":"library(\"Matrix\") library(\"lme4\") library(\"ggplot2\") library(\"eyetrackingR\") ## Loading required package: dplyr ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                         participant_column = \"ParticipantName\",                        trial_column = \"Trial\",                        time_column = \"TimeFromTrialOnset\",                        trackloss_column = \"TrackLoss\",                        aoi_columns = c('Animate','Inanimate'),                        treat_non_aoi_looks_as_missing = TRUE )  # subset to response window post word-onset response_window <- subset_by_window(data,                                      window_start_time = 15500,                                      window_end_time = 21000,                                      rezero = FALSE) ## Avg. window length in new data will be 5500 # analyze amount of trackloss by subjects and trials (trackloss <- trackloss_analysis(data = response_window))  # remove trials with > 25% of trackloss response_window_clean <- clean_by_trackloss(data = response_window, trial_prop_thresh = .25) ## Performing Trackloss Analysis... ## Will exclude trials whose trackloss proportion is greater than : 0.25 ##  ...removed  33  trials. # create Target condition column response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial),                                         yes = 'Inanimate',                                         no  = 'Animate') )"},{"path":"/articles/growth_curve_analysis_vignette.html","id":"visualize-the-timecourse","dir":"Articles","previous_headings":"","what":"Visualize the timecourse","title":"Performing a growth curve analysis using eyetrackingR","text":"analysis, interested change data time. Therefore, ’s important visualize data see whether statistical estimates make sense . plot time-course data, first need convert eyetrackingR’s time_sequence_data format, summarizes data time-bins calculates proportion-looking (use 100ms time bins). , simply use plot method plot time-course.  plot, expect see big differences Target conditions time. However, ideal analysis also consistent observation differences emerged ~500ms – .e, present window onset.","code":"# aggregate across trials within subjects in time analysis response_time <- make_time_sequence_data(response_window_clean, time_bin_size = 100,                                   predictor_columns = c(\"Target\"),                                  aois = \"Animate\"                             )  # visualize time results plot(response_time, predictor_column = \"Target\") +    theme_light() +   coord_cartesian(ylim = c(0,1))"},{"path":"/articles/growth_curve_analysis_vignette.html","id":"growth-curve-analysis","dir":"Articles","previous_headings":"","what":"Growth curve analysis","title":"Performing a growth curve analysis using eyetrackingR","text":"Growth curve analysis (GCA) lets us model timecourse attention fitting curves proportion-looking course trial, statistically assessing bends curves. implementation growth curve analysis modelled Mirman et al. (2008). eyetrackingR sets us nicely GCA. , used make_time_sequence_data generate dataframe. dataframe includes everything need GCA. First, includes dependent variable columns make_time_window_data, giving us option analyzing raw proportions transformations (detail, see documentation window analysis vignette ). Prop – mean raw proportion scores LogitAdjusted – logit transformation, log( Prop / (1-Prop) ), adjusted avoid -/+ infinity Elog – empirical logit transformation log( Prop+e / (1-Prop+e) ) ArcSin – arcsine-root transformation Second, time_sequence_data series columns corresponding ‘orthogonal polynomial timecodes.’ can think linear, quadratic, cubic, etc. component Time predictor (Time, Time^2, Time^3, etc.). However, unlike simply taking power, transformations uncorrelated , therefore appropriate multiple regression. seems confusing, might help simply visualize vectors:  can see linear time code moving bottom left top right corner plot (black). coloured lines corresponds different growth function. idea behind GCA can simulanteously regress differences conditions (, Target) see (combination, independently) best captures pattern growth data. Importantly, uncorrelated, sure capture distinct variance data. Let’s fit first GCA model, including linear time code now (.e., temporarily want ignore non-linear change time): eyetrackingR includes plot method time_sequence_data can easily overlay predictions model raw data:  model reveals two main effects TargetC ot1, respectively. may seem OK first, actually great match data (revealed plot predictions). main effect TargetC says , average throughout trial, participants looked Animate target named Inanimate named. accurate. main effect ot1 says , trial progressed, participants tended look away Animate course trial. also accurate. missing result reflects differences Target emerged start window. remedy issue, can allow non-linear change overtime including higher-order orthogonal polynomials:  model better captures data shows critical interactions Target higher-order polynomials. allow model capture steep drop Inanimate condition well bend follows .","code":"# generate dataframe summarizing values of each vector timecodes <- unique(response_time[, c('ot1','ot2','ot3','ot4','ot5','ot6','ot7')]) timecodes$num <- 1:nrow(timecodes)  ggplot(timecodes, aes(x=num, y=ot1)) +                geom_line() +                geom_line(aes(y=ot2), color='red') +    # quadratic                geom_line(aes(y=ot3), color='blue') +   # cubic                geom_line(aes(y=ot4), color='green') +  # quartic                geom_line(aes(y=ot5), color='purple') + # quintic                 geom_line(aes(y=ot6), color='yellow') + # sextic                geom_line(aes(y=ot7), color='pink') +   # septic                scale_x_continuous(name=\"\") +                scale_y_continuous(name=\"\") round(cor(timecodes[, c(1:7)]),5) ##     ot1 ot2 ot3 ot4 ot5 ot6 ot7 ## ot1   1   0   0   0   0   0   0 ## ot2   0   1   0   0   0   0   0 ## ot3   0   0   1   0   0   0   0 ## ot4   0   0   0   1   0   0   0 ## ot5   0   0   0   0   1   0   0 ## ot6   0   0   0   0   0   1   0 ## ot7   0   0   0   0   0   0   1 # sum-code and center our predictor: response_time$TargetC <- ifelse(response_time$Target == 'Animate', .5, -.5) response_time$TargetC <- as.numeric(scale(response_time$TargetC, center=TRUE, scale=FALSE))  # Construct model model_time_sequence <- lmer(Elog ~ TargetC*(ot1) + (1 + ot1 | Trial) + (1 + ot1 | ParticipantName),                data = response_time, REML = FALSE)  # cleanly show important parts of model (see `summary()` for more) broom.mixed::tidy(model_time_sequence, effects = \"fixed\") ## # A tibble: 4 × 5 ##   effect term        estimate std.error statistic ##   <chr>  <chr>          <dbl>     <dbl>     <dbl> ## 1 fixed  (Intercept)    0.740     0.142      5.21 ## 2 fixed  TargetC        1.76      0.139     12.7  ## 3 fixed  ot1           -3.00      0.634     -4.73 ## 4 fixed  TargetC:ot1   -0.995     0.732     -1.36 drop1(model_time_sequence, ~., test=\"Chi\") ## Single term deletions ##  ## Model: ## Elog ~ TargetC * (ot1) + (1 + ot1 | Trial) + (1 + ot1 | ParticipantName) ##             npar   AIC     LRT   Pr(Chi)     ## <none>           28106                       ## TargetC        1 28123 19.4738  1.02e-05 *** ## ot1            1 28118 14.0063 0.0001822 *** ## TargetC:ot1    1 28105  1.6244 0.2024827     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 plot(response_time, predictor_column = \"Target\", dv = \"Elog\", model = model_time_sequence) +   theme_light() model_time_sequence <- lmer(Elog ~ TargetC*(ot1 + ot2 + ot3 + ot4) + (1 | Trial) + (1 | ParticipantName),                              data = response_time, REML = FALSE)  # commented out because this many random slopes takes too long to fit for a vignette # model_time_sequence <- lmer(Elog ~ TargetC*(ot1 + ot2 + ot3 + ot4) +  #                               (1 + ot1 + ot2 + ot3 + ot4 | Trial) + (1 + ot1 + ot2 + ot3 + ot4 | ParticipantName),  #                             data = response_time, REML = FALSE)  # cleanly show important parts of model (see `summary()` for more) broom.mixed::tidy(model_time_sequence, effects = \"fixed\") ## # A tibble: 10 × 5 ##    effect term        estimate std.error statistic ##    <chr>  <chr>          <dbl>     <dbl>     <dbl> ##  1 fixed  (Intercept)    0.734     0.143      5.13 ##  2 fixed  TargetC        1.76      0.138     12.7  ##  3 fixed  ot1           -2.82      0.193    -14.6  ##  4 fixed  ot2            0.319     0.193      1.65 ##  5 fixed  ot3           -0.584     0.193     -3.03 ##  6 fixed  ot4           -0.325     0.192     -1.69 ##  7 fixed  TargetC:ot1   -0.790     0.401     -1.97 ##  8 fixed  TargetC:ot2   -1.74      0.402     -4.34 ##  9 fixed  TargetC:ot3    4.22      0.401     10.5  ## 10 fixed  TargetC:ot4   -1.82      0.400     -4.54 drop1(model_time_sequence, ~., test=\"Chi\") ## Single term deletions ##  ## Model: ## Elog ~ TargetC * (ot1 + ot2 + ot3 + ot4) + (1 | Trial) + (1 |  ##     ParticipantName) ##             npar   AIC     LRT   Pr(Chi)     ## <none>           28096                       ## TargetC        1 28114  19.327 1.101e-05 *** ## ot1            1 28305 210.511 < 2.2e-16 *** ## ot2            1 28097   2.721  0.099027 .   ## ot3            1 28104   9.184  0.002442 **  ## ot4            1 28097   2.851  0.091310 .   ## TargetC:ot1    1 28098   3.870  0.049159 *   ## TargetC:ot2    1 28113  18.804 1.449e-05 *** ## TargetC:ot3    1 28204 109.693 < 2.2e-16 *** ## TargetC:ot4    1 28115  20.595 5.674e-06 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 plot(response_time, predictor_column = \"Target\", dv = \"Elog\", model = model_time_sequence) +   theme_light()"},{"path":"/articles/growth_curve_analysis_vignette.html","id":"but-when-did-the-conditions-diverge","dir":"Articles","previous_headings":"","what":"But when did the conditions diverge?","title":"Performing a growth curve analysis using eyetrackingR","text":"GCA can tell conditions/predictors predictive value (.e., changed differently) time. can also tell form change seeing polynomials reliably interacted. However, can’t tell time predictors effect. case ascertaining reaction times, one way answer question using onset-contingent analyses. general approaches estimating time windows divergence (estimating onset offset divergences), take look divergence vignette.","code":""},{"path":"/articles/growth_curve_analysis_vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Performing a growth curve analysis using eyetrackingR","text":"Mirman, D., Dixon, J., & Magnuson, J. S. (2008). Statistical computational models visual world paradigm: Growth curves individual differences. Journal Memory Language, 59, 474–494. https://doi.org/10.1016/j.jml.2007.11.006.","code":""},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"overview-of-this-vignette","dir":"Articles","previous_headings":"","what":"Overview of this vignette","title":"Performing an onset-contingent analysis using eyetrackingR","text":"vignette, want examine quickly participants’ looked referent AOI (e.g., Animate, Animate named; Inanimate, Inanimate named) – .e., calculate reaction times. , can perform onset-contingent looking analysis (e.g., Fernald et al., 2008), asking quickly switched AOI looking onset trial happened looking non-target AOI. participants faster switch distractor AOI target AOI vice-verse, can conclude reliably identifying target AOI. Moreover, can ask effect onset-AOI (switching /target) interacts another predictor. priori, suspect slower switch away Animate (.e., Inanimate named) switch Animate (.e., Animate named) , things equal, infants prefer look animate things.","code":""},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Performing an onset-contingent analysis using eyetrackingR","text":"performing analysis, ’ll need prepare clean dataset. quickly notes , information, see vignette preparing data.","code":"set.seed(42) library(\"Matrix\") library(\"lme4\") library(\"ggplot2\") library(\"eyetrackingR\") ## Loading required package: dplyr ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                         participant_column = \"ParticipantName\",                        trial_column = \"Trial\",                        time_column = \"TimeFromTrialOnset\",                        trackloss_column = \"TrackLoss\",                        aoi_columns = c('Animate','Inanimate'),                        treat_non_aoi_looks_as_missing = TRUE )  # subset to response window post word-onset response_window <- subset_by_window(data,                                      window_start_time = 15500,                                      window_end_time = 21000,                                      rezero = FALSE) ## Avg. window length in new data will be 5500 # analyze amount of trackloss by subjects and trials (trackloss <- trackloss_analysis(data = response_window))  # remove trials with > 25% of trackloss response_window_clean <- clean_by_trackloss(data = response_window, trial_prop_thresh = .25) ## Performing Trackloss Analysis... ## Will exclude trials whose trackloss proportion is greater than : 0.25 ##  ...removed  33  trials. # create Target condition column response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial),                                         yes = 'Inanimate',                                         no  = 'Animate') )"},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"adding-new-columns","dir":"Articles","previous_headings":"","what":"Adding new columns","title":"Performing an onset-contingent analysis using eyetrackingR","text":"order perform analysis, need add two new columns dataset indicate Target Distractor AOIs relative Target condition trial.","code":"# recode AOIs to target & distractor response_window_clean$TrialTarget <- ifelse(test = response_window_clean$Target == 'Animate',                                              yes = response_window_clean$Animate,                                              no = response_window_clean$Inanimate) response_window_clean$TrialDistractor <- ifelse(test = response_window_clean$Target == 'Animate',                                                  yes = response_window_clean$Inanimate,                                                  no = response_window_clean$Animate)"},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"visualize-switches-from-an-onset-aoi-to-the-target-aoi","dir":"Articles","previous_headings":"","what":"Visualize switches from an onset AOI to the target AOI","title":"Performing an onset-contingent analysis using eyetrackingR","text":"Next, can use make_onset_data calculate whether, point trial, participant switched onset AOI. can plot new dataframe showing proportion participants switched onset AOI point (style adapted Yurovsky & Frank, 2015). size gap solid line (switching non-Target) dashed line (switching Target) documents infants’ performance identifying target: Infants switch quickly frequently Target :  specify predictor plot, can examine visually whether infants’ performance identifying target varied predictor. , want know whether reliably switched target Target Animate versus Inanimate:  Infants definitely consistent faster switching Animate named away Inanimate named, expected. Finally, can ask whether infants higher vocabularies outperformed infants lower vocabularies, indicated MCDI scores (note, visualizing, plot method performs median split):  one expect, infants larger vocabularies faster (consistent) identifying Target AOI.","code":"onsets <- make_onset_data(response_window_clean, onset_time = 15500, target_aoi='TrialTarget') # participants' ability to orient to the trial target overall: plot(onsets) + theme(legend.text=element_text(size=5)) # participants' ability to orient to the trial target, split by which target: plot(onsets, predictor_columns = \"Target\") + theme(legend.text=element_text(size=6)) # we can also visualize numeric predictors: plot(onsets, predictor_columns = \"MCDI_Total\") + theme(legend.text=element_text(size=6)) ## Column 'MCDI_Total' is numeric, performing median split for visualization."},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"analyze-onset-contingent-switch-times","dir":"Articles","previous_headings":"","what":"Analyze onset-contingent switch times","title":"Performing an onset-contingent analysis using eyetrackingR","text":"order analyze switch times, can calculate switch times target non-target onset trials using make_switch_data. can use linear mixed-effects model test three hypotheses: infants faster/slower switching target away target (main effect FirstAOI) infants faster/slower switch target Animate Inanimate (main effect Target). infants faster/slower switching target Animate Inanimate (interaction FirstAOI:Target)  main effect FirstAOIC reveals participants likely switch target away , overall, suggests overall identify target referent words. interaction TargetC, however, reveals infants faster switch Animate named away Animate Inanimate named.","code":"onset_switches <- make_switch_data(onsets, predictor_columns = \"Target\")  # visualize subject's switch times plot(onset_switches, predictor_columns = c(\"Target\")) # center predictor: onset_switches$FirstAOIC <- ifelse(onset_switches$FirstAOI == 'TrialTarget', .5, -.5) onset_switches$FirstAOIC <- scale(onset_switches$FirstAOIC, center=TRUE, scale=FALSE)  onset_switches$TargetC <- ifelse(onset_switches$Target == 'Animate', .5, -.5) onset_switches$TargetC <- scale(onset_switches$TargetC, center=TRUE, scale=FALSE)   # build model: model_switches <- lmer(FirstSwitch ~ FirstAOIC*TargetC +                  (1 | Trial) + (1 | ParticipantName), data=onset_switches, REML=FALSE) # cleanly show important parts of model (see `summary()` for more) broom.mixed::tidy(model_switches, effects=\"fixed\") ## # A tibble: 4 × 5 ##   effect term              estimate std.error statistic ##   <chr>  <chr>                <dbl>     <dbl>     <dbl> ## 1 fixed  (Intercept)        17017.       152.   112.    ## 2 fixed  FirstAOIC           1720.       239.     7.21  ## 3 fixed  TargetC               61.0      251.     0.243 ## 4 fixed  FirstAOIC:TargetC   2062.       520.     3.96 drop1(model_switches,~.,test=\"Chi\") ## boundary (singular) fit: see ?isSingular ## Single term deletions ##  ## Model: ## FirstSwitch ~ FirstAOIC * TargetC + (1 | Trial) + (1 | ParticipantName) ##                   npar    AIC    LRT   Pr(Chi)     ## <none>                 1752.0                      ## FirstAOIC            1 1789.4 39.391 3.469e-10 *** ## TargetC              1 1750.1  0.059 0.8084704     ## FirstAOIC:TargetC    1 1763.2 13.230 0.0002755 *** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/onset_contingent_analysis_vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Performing an onset-contingent analysis using eyetrackingR","text":"Fernald, ., Zangl, R., Portillo, . L., & Marchman, V. . (2008). Looking listening: Using eye movements monitor spoken language comprehension infants young children. . . Sekerina, E. M. Fernández, & H. Clahsen (Eds.), Developmental Psycholinguistics: -line methods children’s language processing (pp. 97–135). Amsterdam: John Benjamins. Yurovsky, D., & Frank, M. C. (2015). Beyond Naïve Cue Combination: Salience Social Cues Early Word Learning. Developmental Science, 1–38.","code":""},{"path":"/articles/preparing_your_data_vignette.html","id":"overview-of-this-vignette","dir":"Articles","previous_headings":"","what":"Overview of this vignette","title":"Preparing your data for use with eyetrackingR","text":"vignette cover basics preparing data use eyetrackingR.","code":""},{"path":"/articles/preparing_your_data_vignette.html","id":"your-data","dir":"Articles","previous_headings":"Overview of this vignette","what":"Your Data","title":"Preparing your data for use with eyetrackingR","text":"eyetrackingR designed deal data (relatively) raw form, row specifies sample. row represent equally spaced unit time (e.g., eye-tracker’s sample rate 100hz, row corresponds eye-position every 10ms). contrast parsed data software bundled eye-trackers can sometimes output (e.g., already parsed saccades fixations). eyetrackingR, simplest data best. also maximizes compatibility: eyetrackingR work eye-tracker’s data (e.g., Eyelink, Tobii, etc.), since requires basic format. Note: eyetrackingR handle reading data R. software bundled eyetracker capable exporting data delimited format (.csv, tab-delimited .txt), etc. , can use base functions like read.delim, (recommended) check package readr. eyetrackingR just needs following columns: Participant Columns: Specifies unique code participant (e.g., ‘SUBJ101’) Trial Columns: Specifies unique name number trial. experiments subject sees item , can either name (e.g., ‘HORSE-DOG’) number (e.g., trial 1, 2, 3, etc.). trials see items multiple times, almost always number. Timestamp Column: Specifies cumulative time passed within trial (e.g., milliseconds: 0, 50, 100, …, 1500). column specifies time-within-trial. timestamp column, beginning timestamp doesn’t correspond beginning trial way ’d like, function subset_by_window can help fix . AOI Column(s): (Note: don’t columns, function add_aoi can create – see .) columns specify whether gaze particular ‘Area Interest.’ AOI corresponding column. elements column specify, sample, whether participant’s gaze AOI. Trackloss Column: Specifies, sample, whether eye-tracker lost eyes sample. Helpful cleaning data removing unreliable trials. See clean_by_trackloss . also optional columns, might want use depending analysis: Item column(s): corresponds ‘items’ experiment: types stimuli presented across trials. likely always name (e.g., ‘HORSE-DOG’) , unlike ‘Trial’ column, need unique. Miscellaneous predictor column(s): columns specifying predictors (e.g., Condition, Age, Sex). Unlike types , specified separately analysis, outset). dataset columns, ’re ready begin using eyetrackingR.","code":""},{"path":[]},{"path":"/articles/preparing_your_data_vignette.html","id":"load-dataset-and-dependencies-set-data-options-for-eyetrackingr-","dir":"Articles","previous_headings":"Data Preparation","what":"Load dataset and dependencies, set data options for eyetrackingR.","title":"Preparing your data for use with eyetrackingR","text":"used eyetrackingR, data must run make_eyetrackingr_data function. lets provide information dataset just described . function perform checks data make sure ’s correct format. dataset, participant saw item experiment, trial_column specifies unique name trial (e.g., “FamiliarCow”) don’t specify item_column.","code":"set.seed(42)  library(\"Matrix\") library(\"lme4\") library(\"ggplot2\") library(\"eyetrackingR\") ## Loading required package: dplyr ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )"},{"path":"/articles/preparing_your_data_vignette.html","id":"dealing-with-non-aoi-looks","dir":"Articles","previous_headings":"Data Preparation > Load dataset and dependencies, set data options for eyetrackingR.","what":"Dealing with Non-AOI Looks","title":"Preparing your data for use with eyetrackingR","text":"might wondering treat_non_aoi_looks_as_missing argument . Almost eyetracking analyses require calculating proportion looking–across trial, within time bin, etc. One important choice researcher make whether include non-AOI looking calculation. two options: Treat Non-AOI Looks Missing Data. many visual world paradigms, move reflects assumption looking blank portion screen might well considered trackloss. main advantage technique makes analyses focusing tradeoff two AOI easily interpretable. Without treating outside looks trackloss, can difficult interpret increase looking single AOI across conditions. due overall increase attention (, looking AOIs, including one interest, increased)? due increase preference AOI specifically? Treat Non-AOI Looks Valid Data tradeoff , interested overall attention AOIs across conditions, previous approach obscure difference. alternative treat non-AOI looks valid. argument treat_non_aoi_looks_as_missing lets decide options eyetrackingR . set TRUE, comes time eyetrackingR calculate proportion looking AOI, calculated “time looking AOI divided time looking AOIs.” contrast, parameter set FALSE, proportion looking AOI calculated “time looking AOI divided total time looking (excluding actual trackloss).”","code":""},{"path":"/articles/preparing_your_data_vignette.html","id":"cleaning-up-messy-data","dir":"Articles","previous_headings":"Data Preparation","what":"Cleaning Up Messy Data:","title":"Preparing your data for use with eyetrackingR","text":"wish data came right eye-tracker ready analysis, isn’t always case. Two annoying problems might encounter : data doesn’t columns corresponding areas--interest. Maybe needed create revise running experiment, eyetracking software just doesn’t let specify . data doesn’t specify relevant things trial start. Experiments complicated. pre-phases, fixation-contigent attention-getters, etc. etc. means stuff actually want analyze within trial buried among lots irrelevant data. example, might want analyze data stimulus presentation, stimuli starts different timepoint trial. Luckily, eyetrackingR tools address problems","code":""},{"path":"/articles/preparing_your_data_vignette.html","id":"adding-an-area-of-interest","dir":"Articles","previous_headings":"Data Preparation > Cleaning Up Messy Data:","what":"Adding an Area-of-Interest","title":"Preparing your data for use with eyetrackingR","text":"eyetracking data doesn’t columns corresponding areas interest. However, columns give x,y gaze coordinates. also csv file AOI, specifying boundaries type trial. case, ’s easy add AOIs dataframe: can done AOI: just load csv file run add_aoi function . using function, probably check added AOI column actually indicates gaze ever AOI. example: (Note typically add AOIs dataframe running make_eyetrackingr_data, since function check AOIs.)","code":"animate_aoi <- read.csv(\"./interest_areas_for_animate_aoi.csv\")  #            Trial Left Top Right Bottom # 1   FamiliarBird  500 100   900    500 # 2 FamiliarBottle  400 200   800    600 # 3    FamiliarCow  500 300   900    700 # 4    FamiliarDog  300 100   700    500 # 5  FamiliarHorse  500 200   900    600 # 6  FamiliarSpoon  350 300   750    700  data <- add_aoi(data = data, aoi_dataframe = animate_aoi,                 x_col = \"GazeX\", y_col = \"GazeY\",                 aoi_name = \"Animate\",                x_min_col = \"Left\", x_max_col = \"Right\", y_min_col = \"Top\", y_max_col = \"Bottom\") table(data$Animate) ##  ## FALSE  TRUE  ## 49681 82460 table(is.na(data$Animate)) # if all TRUE, then something went wrong. ##  ##  FALSE   TRUE  ## 132141  63771"},{"path":"/articles/preparing_your_data_vignette.html","id":"subsetting-into-the-time-window-of-interest-across-trials","dir":"Articles","previous_headings":"Data Preparation > Cleaning Up Messy Data:","what":"Subsetting into the Time-Window of Interest Across Trials","title":"Preparing your data for use with eyetrackingR","text":"eyetrackingR’s subset_by_window several methods getting data ’re interested . powerful can used repeatedly/iteratively home relevant data. show . example, let’s imagine Timestamp doesn’t actually specify start trial– instead, specifies time since eye-tracker turned ! Fortunately, eye-tracker sends message trial starts (always first sample trial– recording often starts hundred milliseconds trial ). message can used set zero-point trial. Unfortunately, eye-tracker didn’t send message response-window starts. Instead, added column tells long start trial response-window started. Now rezero’d data 0 = trial-start, column specifying time trial start can used easily. Finally, trials always ended 21 seconds. ’ll simply remove data . summary, subset data focus time window interest.","code":"data <- subset_by_window(data, window_start_msg = \"TrialStart\", msg_col = \"Message\", rezero= TRUE) response_window <- subset_by_window(data, window_start_col = \"ResponseWindowStart\", rezero= FALSE, remove= TRUE) response_window <- subset_by_window(response_window, window_end_time = 21000, rezero= FALSE, remove= TRUE)"},{"path":"/articles/preparing_your_data_vignette.html","id":"dealing-with-trackloss","dir":"Articles","previous_headings":"Data Preparation","what":"Dealing with trackloss","title":"Preparing your data for use with eyetrackingR","text":"Trackloss occurs eye-tracker loses track participant’s eyes (e.g., turn away blink) captures gaze location low validity. need decide trials remove () due high trackloss. , : Calculate amount trackloss trial Remove trials 25% trackloss","code":"# analyze amount of trackloss by subjects and trials (trackloss <- trackloss_analysis(data = response_window)) ## # A tibble: 155 × 6 ##    ParticipantName Trial          Samples TracklossSamples TracklossForTrial ##    <fct>           <fct>            <dbl>            <dbl>             <dbl> ##  1 ANCAT139        FamiliarBottle     330              161            0.488  ##  2 ANCAT18         FamiliarBird       330               74            0.224  ##  3 ANCAT18         FamiliarBottle     330               43            0.130  ##  4 ANCAT18         FamiliarCow        330              159            0.482  ##  5 ANCAT18         FamiliarDog        330               95            0.288  ##  6 ANCAT18         FamiliarHorse      330              165            0.5    ##  7 ANCAT18         FamiliarSpoon      330               95            0.288  ##  8 ANCAT22         FamiliarBird       330               14            0.0424 ##  9 ANCAT22         FamiliarBottle     330                8            0.0242 ## 10 ANCAT22         FamiliarDog        330               55            0.167  ## # … with 145 more rows, and 1 more variable: TracklossForParticipant <dbl> response_window_clean <- clean_by_trackloss(data = response_window, trial_prop_thresh = .25) ## Performing Trackloss Analysis... ## Will exclude trials whose trackloss proportion is greater than : 0.25 ##  ...removed  33  trials."},{"path":"/articles/preparing_your_data_vignette.html","id":"how-much-data-are-we-left-with","dir":"Articles","previous_headings":"Data Preparation","what":"How much data are we left with?","title":"Preparing your data for use with eyetrackingR","text":"data cleaning, ’s important assess much data ultimately left () report along findings , (b) identify problematic participants didn’t contribute enough trials reliably estimate performance.","code":""},{"path":"/articles/preparing_your_data_vignette.html","id":"assess-mean-trackloss-for-each-participant","dir":"Articles","previous_headings":"Data Preparation > How much data are we left with?","what":"Assess mean trackloss for each participant","title":"Preparing your data for use with eyetrackingR","text":"","code":"trackloss_clean <- trackloss_analysis(data = response_window_clean)  (trackloss_clean_subjects <- unique(trackloss_clean[, c('ParticipantName','TracklossForParticipant')])) ## # A tibble: 27 × 2 ##    ParticipantName TracklossForParticipant ##    <fct>                             <dbl> ##  1 ANCAT18                          0.177  ##  2 ANCAT22                          0.0588 ##  3 ANCAT23                          0.0626 ##  4 ANCAT26                          0.0970 ##  5 ANCAT39                          0.0379 ##  6 ANCAT45                          0.0131 ##  7 ANCAT50                          0.0576 ##  8 ANCAT53                          0.0485 ##  9 ANCAT55                          0.0430 ## 10 ANCAT58                          0.0261 ## # … with 17 more rows"},{"path":"/articles/preparing_your_data_vignette.html","id":"summarize-samples-contributed-per-trial","dir":"Articles","previous_headings":"Data Preparation > How much data are we left with?","what":"Summarize samples contributed per trial","title":"Preparing your data for use with eyetrackingR","text":"","code":"# get mean samples contributed per trials, with SD mean(1 - trackloss_clean_subjects$TracklossForParticipant) ## [1] 0.9313075 sd(1- trackloss_clean_subjects$TracklossForParticipant) ## [1] 0.05208985"},{"path":"/articles/preparing_your_data_vignette.html","id":"assess-number-of-trials-contributed-by-each-participant","dir":"Articles","previous_headings":"Data Preparation > How much data are we left with?","what":"Assess number of trials contributed by each participant","title":"Preparing your data for use with eyetrackingR","text":"","code":"# look at the NumTrials column (final_summary <- describe_data(response_window_clean, describe_column = 'Animate', group_columns = 'ParticipantName')) ## # A tibble: 27 × 9 ##    ParticipantName  Mean    SD LowerQ UpperQ   Min   Max     N NumTrials ##    <fct>           <dbl> <dbl>  <dbl>  <dbl> <int> <int> <int>     <int> ##  1 ANCAT18         0.169 0.375      0      1     0     1   660         2 ##  2 ANCAT22         0.581 0.494      0      1     0     1  1650         5 ##  3 ANCAT23         0.780 0.414      0      1     0     1  1980         6 ##  4 ANCAT26         0.598 0.490      0      1     0     1  1320         4 ##  5 ANCAT39         0.650 0.477      0      1     0     1  1980         6 ##  6 ANCAT45         0.679 0.467      0      1     0     1   990         3 ##  7 ANCAT50         0.836 0.370      0      1     0     1   990         3 ##  8 ANCAT53         0.737 0.441      0      1     0     1   990         3 ##  9 ANCAT55         0.745 0.436      0      1     0     1  1650         5 ## 10 ANCAT58         0.731 0.443      0      1     0     1  1650         5 ## # … with 17 more rows"},{"path":"/articles/preparing_your_data_vignette.html","id":"summarize-number-of-trials-contributed","dir":"Articles","previous_headings":"Data Preparation > How much data are we left with?","what":"Summarize number of trials contributed","title":"Preparing your data for use with eyetrackingR","text":"","code":"mean(final_summary$NumTrials) ## [1] 4.518519 sd(final_summary$NumTrials) ## [1] 1.369176"},{"path":"/articles/preparing_your_data_vignette.html","id":"create-additional-columns-needed-for-analysis","dir":"Articles","previous_headings":"Data Preparation","what":"Create additional columns needed for analysis","title":"Preparing your data for use with eyetrackingR","text":"Now time make sure columns needed analyses, dataset going shaped subsetted analyze data ’s easier add columns derivative datasets. present experiment, one thing want create “Target” condition column based name Trial. trial, participant told look either Animate Inanimate objects. create column specifying column. dataset now ready analysis!","code":"response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial),                                         yes = 'Inanimate',                                         no  = 'Animate') )"},{"path":"/articles/window_analysis_vignette.html","id":"overview-of-this-vignette","dir":"Articles","previous_headings":"","what":"Overview of this vignette","title":"Performing a window analysis using eyetrackingR","text":"vignette, want take initial look data perform fundamental eye-tracking analysis : window analysis. allows us ascertain whether, certain window, infants looked ‘animate’ named ‘inanimate’ named.","code":""},{"path":"/articles/window_analysis_vignette.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Performing a window analysis using eyetrackingR","text":"performing analysis, ’ll need prepare clean dataset. quickly notes , information, see vignette preparing data.","code":"set.seed(42)  library(\"Matrix\") library(\"lme4\") library(\"ggplot2\") library(\"eyetrackingR\") ## Loading required package: dplyr ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                         participant_column = \"ParticipantName\",                        trial_column = \"Trial\",                        time_column = \"TimeFromTrialOnset\",                        trackloss_column = \"TrackLoss\",                        aoi_columns = c('Animate','Inanimate'),                        treat_non_aoi_looks_as_missing = TRUE ) # subset to response window post word-onset response_window <- subset_by_window(data,                                      window_start_time = 15500,                                      window_end_time = 21000,                                      rezero = FALSE) ## Avg. window length in new data will be 5500 # remove trials with > 25% of trackloss response_window_clean <- clean_by_trackloss(data = response_window,                                             trial_prop_thresh = .25) ## Performing Trackloss Analysis... ## Will exclude trials whose trackloss proportion is greater than : 0.25 ##  ...removed  33  trials. # create Target condition column response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial),                                         yes = 'Inanimate',                                         no  = 'Animate') )"},{"path":"/articles/window_analysis_vignette.html","id":"sanity-checks","dir":"Articles","previous_headings":"","what":"Sanity checks","title":"Performing a window analysis using eyetrackingR","text":", ’ll inspect descriptive statistics data, make initial visualizations just make sure everything order. basically want glance subject’s looking Animate condition. , ’ll: use describe_data function generate quick data summary (telling us means variance within Target condition subject, number trials contributed cleaning ), quickly visualize differences plotting line subject. expect slope direction, lower mean looking Animate Inanimate named Animate named.","code":"(data_summary <- describe_data(response_window_clean,                                 describe_column='Animate', group_columns=c('Target','ParticipantName'))) ## # A tibble: 54 × 10 ##    Target  ParticipantName  Mean    SD LowerQ UpperQ   Min   Max     N NumTrials ##    <fct>   <fct>           <dbl> <dbl>  <dbl>  <dbl> <int> <int> <int>     <int> ##  1 Animate ANCAT18         0.359 0.481      0      1     0     1   330         1 ##  2 Animate ANCAT22         0.791 0.407      0      1     0     1   990         3 ##  3 Animate ANCAT23         0.815 0.388      0      1     0     1  1320         4 ##  4 Animate ANCAT26         0.699 0.459      0      1     0     1   660         2 ##  5 Animate ANCAT39         0.880 0.325      0      1     0     1  1320         4 ##  6 Animate ANCAT45         0.715 0.452      0      1     0     1   660         2 ##  7 Animate ANCAT50         0.896 0.306      0      1     0     1   660         2 ##  8 Animate ANCAT53         0.727 0.446      0      1     0     1   660         2 ##  9 Animate ANCAT55         0.955 0.208      0      1     0     1   990         3 ## 10 Animate ANCAT58         0.855 0.352      0      1     0     1  1320         4 ## # … with 44 more rows plot(data_summary)"},{"path":"/articles/window_analysis_vignette.html","id":"performing-a-simple-paired-t-test","dir":"Articles","previous_headings":"","what":"Performing a simple paired t-test","title":"Performing a window analysis using eyetrackingR","text":"first way ask question get single mean proportion score (looking Animate AOI) Target condition (Animate, Inanimate) subject perform paired t-test. , use make_time_window_data function aggregate participant calculate mean value. also specify couple additional predictors (Age, MCDI_Total [vocabulary score]) use follow-analysis. Note dataframe returned make_time_window_data actually give us different dependent variables choose : Prop – mean raw proportion-looking LogitAdjusted – logit defined log( Prop / (1 - Prop) ). transformation attempts map bounded 0,1 data real number line. Unfortunately, data exactly 0 1, undefined. One solution add small value datapoints equal 0, subtract small value datapoints equal 1 (use 1/2 smallest nonzero value adjustment). Elog – Another way calculating corrected logit transformation add small value epsilon numerator denominator logit equation (use 0.5). ArcSin – arcsine-root transformation raw proportions, defined asin(sqrt(Prop)). first DV intuitive, might consider using others account bounded nature proportions. boundedness proportions issue can mean CI’s around estimates fall 1 0 (possible) inherent link group means variance (means closer 0 1 necessarily lower variance means around .5). violations many parametric models, OLS regression t-tests. (EyetrackingR also lets specify arbitrary DV aside . example, analyze mean pupil-dilation supplying column name other_dv_columns argument. true make_time_sequence_data well.) start using ArcSin DV.  t-test looks pretty good. also want know whether effect Target mediated age vocabulary. , can fit quick linear model: linear model shows main effects interactions Target predictors, confirms large effect Target.","code":"# aggregate by subject across the response window response_window_agg_by_sub <- make_time_window_data(response_window_clean,                                                      aois='Animate',                                                     predictor_columns=c('Target','Age','MCDI_Total'),                                                     summarize_by = \"ParticipantName\")  # take a quick peek at data plot(response_window_agg_by_sub, predictor_columns=\"Target\", dv = \"ArcSin\") # show condition means describe_data(response_window_agg_by_sub, describe_column = \"ArcSin\", group_columns = \"Target\") ## # A tibble: 2 × 8 ##   Target     Mean    SD LowerQ UpperQ   Min   Max     N ##   <fct>     <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <int> ## 1 Animate   1.08  0.206  0.653   1.43 0.643  1.57    27 ## 2 Inanimate 0.692 0.248  0.186   1.08 0      1.14    27 # simple paired t-test between conditions t.test(ArcSin ~ Target, data= response_window_agg_by_sub, paired=TRUE) ##  ##  Paired t-test ##  ## data:  ArcSin by Target ## t = 7.2705, df = 26, p-value = 1.012e-07 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ##  0.2803975 0.5014410 ## sample estimates: ## mean of the differences  ##               0.3909192 # you should almost always sum-code and center your predictors when performing regression analyses response_window_agg_by_sub$AgeC <- response_window_agg_by_sub$Age - mean(response_window_agg_by_sub$Age) response_window_agg_by_sub$MCDI_TotalC <- response_window_agg_by_sub$MCDI_Total - mean(response_window_agg_by_sub$MCDI_Total)  model <- lm(ArcSin ~ Target*AgeC*MCDI_TotalC, data=response_window_agg_by_sub) summary(model) ##  ## Call: ## lm(formula = ArcSin ~ Target * AgeC * MCDI_TotalC, data = response_window_agg_by_sub) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -0.43847 -0.14408 -0.01695  0.14882  0.48809  ##  ## Coefficients: ##                                    Estimate Std. Error t value Pr(>|t|)     ## (Intercept)                       1.0775721  0.0462383  23.305  < 2e-16 *** ## TargetInanimate                  -0.4054232  0.0653909  -6.200 1.45e-07 *** ## AgeC                              0.0315232  0.0413260   0.763    0.449     ## MCDI_TotalC                      -0.0014167  0.0033328  -0.425    0.673     ## TargetInanimate:AgeC             -0.0012671  0.0584438  -0.022    0.983     ## TargetInanimate:MCDI_TotalC      -0.0040145  0.0047133  -0.852    0.399     ## AgeC:MCDI_TotalC                  0.0009042  0.0025599   0.353    0.726     ## TargetInanimate:AgeC:MCDI_TotalC  0.0024107  0.0036202   0.666    0.509     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 0.2265 on 46 degrees of freedom ## Multiple R-squared:  0.5045, Adjusted R-squared:  0.4291  ## F-statistic: 6.691 on 7 and 46 DF,  p-value: 1.777e-05"},{"path":"/articles/window_analysis_vignette.html","id":"using-mixed-effects-models","dir":"Articles","previous_headings":"","what":"Using mixed-effects models","title":"Performing a window analysis using eyetrackingR","text":"rigorous approach aggregate participants , instead, aggregate trials within participants fit linear mixed-effects model using lme4’s lmer function. predicts infants’ looking Animate AOI based Target condition trial accounting random intercepts slope across Trial (.e., items) ParticipantName (.e., subjects). , demonstration’s sake, ’ll predict Elog transformed DV. Note make_time_window_data call longer summarizes Participant. summarize_by argument passed, function default summarizing trials within participants. results look much line results simple t-test, though slightly conservative.","code":"response_window_agg <- make_time_window_data(response_window_clean,                                               aois='Animate',                                               predictor_columns=c('Target','Age','MCDI_Total'))  # sum-code and center predictors response_window_agg$TargetC <- ifelse(response_window_agg$Target == 'Animate', .5, -.5) response_window_agg$TargetC <- as.numeric(scale(response_window_agg$TargetC, center=TRUE, scale=FALSE))  # mixed-effects linear model on subject*trial data model_time_window <- lmer(Elog ~ TargetC + (1 + TargetC | Trial) + (1 | ParticipantName),                            data = response_window_agg, REML = FALSE) ## boundary (singular) fit: see ?isSingular # cleanly show important parts of model (see `summary()` for more) (est <- broom.mixed::tidy(model_time_window, effects=\"fixed\")) ## # A tibble: 2 × 5 ##   effect term        estimate std.error statistic ##   <chr>  <chr>          <dbl>     <dbl>     <dbl> ## 1 fixed  (Intercept)     1.15     0.206      5.57 ## 2 fixed  TargetC         2.48     0.323      7.66 # use model comparison to attain p-values drop1(model_time_window,~.,test=\"Chi\") ## Single term deletions ##  ## Model: ## Elog ~ TargetC + (1 + TargetC | Trial) + (1 | ParticipantName) ##         npar    AIC    LRT  Pr(Chi)    ## <none>       505.40                    ## TargetC    1 512.35 8.9491 0.002776 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/window_analysis_vignette.html","id":"interpreting-the-estimates","dir":"Articles","previous_headings":"Using mixed-effects models","what":"Interpreting the estimates","title":"Performing a window analysis using eyetrackingR","text":"estimates lmer can interpreted follows: (Intercept) – overall log-odds looking Animate regardless Target condition? TargetC – difference log-odds two conditions’ looking Animate? sum-coded TargetC predictor fitting model, can calculate looking Animate Animate target condition taking intercept estimate, +/- slope estimate divided two. can convert back proportion value reversing transformation log-odds: might notice higher might expected, based raw proportions (actual proportion-looking animate condition closer .80). suggest choice transformation (empirical logit) problematic. ’s important choose transformation satisfies assumptions model using. can plot fitted vs. residuals model using plot method lmer:  empirical-logit transformation appears created problematic outliers, might want consider another transformation, adjusted logit.  See Wharton & Hui (2011) discussion issues.","code":"condition_estimate <- with(est,                             c(estimate[term==\"(Intercept)\"] + estimate[term==\"TargetC\"] / 2,                              estimate[term==\"(Intercept)\"] - estimate[term==\"TargetC\"] / 2)) exp(condition_estimate)/(1+exp(condition_estimate)) ## [1] 0.9155565 0.4767013 plot(model_time_window) model_time_window_logit <- lmer(LogitAdjusted ~ TargetC + (1 + TargetC | Trial) + (1 | ParticipantName),                                  data = response_window_agg, REML = FALSE) ## boundary (singular) fit: see ?isSingular plot(model_time_window_logit) drop1(model_time_window_logit,~.,test=\"Chi\") ## Single term deletions ##  ## Model: ## LogitAdjusted ~ TargetC + (1 + TargetC | Trial) + (1 | ParticipantName) ##         npar    AIC    LRT  Pr(Chi)    ## <none>       382.11                    ## TargetC    1 389.80 9.6917 0.001851 ** ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 est_logit <- broom.mixed::tidy(model_time_window_logit, effects=\"fixed\") condition_estimate_logit <- with(est_logit,                             c(estimate[term==\"(Intercept)\"] + estimate[term==\"TargetC\"] / 2,                              estimate[term==\"(Intercept)\"] - estimate[term==\"TargetC\"] / 2)) exp(condition_estimate_logit)/(1+exp(condition_estimate_logit)) ## [1] 0.8620136 0.4741567"},{"path":"/articles/window_analysis_vignette.html","id":"adding-additional-predictors","dir":"Articles","previous_headings":"Using mixed-effects models","what":"Adding additional predictors","title":"Performing a window analysis using eyetrackingR","text":"can also throw additional predictors model, , long specified columns called make_time_window_data. look effect Age MCDI_Total (centering, course): see effect MCDI_Total (participants’ productive vocabulary): participants larger vocabularies looked less Animate overall (regardless Target).","code":"response_window_agg$AgeC <- response_window_agg$Age - mean(response_window_agg$Age) response_window_agg$MCDI_TotalC <- response_window_agg$MCDI_Total - mean(response_window_agg$MCDI_Total)  model_time_window_add_predictors <- lmer(Elog ~ TargetC*AgeC*MCDI_TotalC + (1 + TargetC | Trial) + (1 | ParticipantName),                data = response_window_agg, REML = FALSE) ## boundary (singular) fit: see ?isSingular # cleanly show important parts of model (see `summary()` for more) broom.mixed::tidy(model_time_window_add_predictors, effects=\"fixed\") ## # A tibble: 8 × 5 ##   effect term                     estimate std.error statistic ##   <chr>  <chr>                       <dbl>     <dbl>     <dbl> ## 1 fixed  (Intercept)               1.14       0.201     5.66   ## 2 fixed  TargetC                   2.74       0.353     7.77   ## 3 fixed  AgeC                      0.229      0.173     1.32   ## 4 fixed  MCDI_TotalC              -0.0336     0.0145   -2.33   ## 5 fixed  TargetC:AgeC              0.0802     0.303     0.265  ## 6 fixed  TargetC:MCDI_TotalC      -0.00126    0.0252   -0.0498 ## 7 fixed  AgeC:MCDI_TotalC          0.00263    0.0106    0.249  ## 8 fixed  TargetC:AgeC:MCDI_TotalC -0.0296     0.0183   -1.62 # use model comparison to attain p-values drop1(model_time_window_add_predictors,~.,test=\"Chi\") ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## boundary (singular) fit: see ?isSingular ## Single term deletions ##  ## Model: ## Elog ~ TargetC * AgeC * MCDI_TotalC + (1 + TargetC | Trial) +  ##     (1 | ParticipantName) ##                          npar    AIC    LRT  Pr(Chi)    ## <none>                        509.26                    ## TargetC                     1 516.59 9.3312 0.002253 ** ## AgeC                        1 508.95 1.6957 0.192848    ## MCDI_TotalC                 1 512.14 4.8815 0.027146 *  ## TargetC:AgeC                1 507.33 0.0695 0.792084    ## TargetC:MCDI_TotalC         1 507.26 0.0025 0.960331    ## AgeC:MCDI_TotalC            1 507.32 0.0620 0.803385    ## TargetC:AgeC:MCDI_TotalC    1 509.85 2.5966 0.107095    ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"/articles/window_analysis_vignette.html","id":"additional-information","dir":"Articles","previous_headings":"Using mixed-effects models","what":"Additional information","title":"Performing a window analysis using eyetrackingR","text":"basic introduction linear mixed-effects models, covering topics like p-values, confidence intervals, estimates, interpreting random effects, logistic regression, see tutorial. information empirical-logit transformation, see Barr (2008). information dangers analyzing raw proportion means, see Dixon (2008) Jaeger (2008).","code":""},{"path":"/articles/window_analysis_vignette.html","id":"a-word-of-caution-about-window-analyses","dir":"Articles","previous_headings":"","what":"A word of caution about window analyses","title":"Performing a window analysis using eyetrackingR","text":"important consider losing window analysis. collapsing across time within trials subjects, completely removing greatest asset eye-tracking data: time. can mask important properties data. Therefore, window analyses attractive terms parsimony computational demands – often necessary first step – analyses may allow better understand report data.","code":""},{"path":"/articles/window_analysis_vignette.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Performing a window analysis using eyetrackingR","text":"Barr, D. J. (2008). Analyzing “visual world” eyetracking data using multilevel logistic regression. Journal Memory Language, 59, 457–474. https://doi.org/10.1016/j.jml.2007.09.002 Dixon, P. (2008). Models accuracy repeated-measures designs. Journal Memory Language, 59(4), 447–456. https://doi.org/10.1016/j.jml.2007.11.004 Jaeger, T. F. (2008). Categorical data analysis: Away ANOVAs (transformation ) towards logit mixed models. Journal Memory Language, 59(434-446). https://doi.org/10.1016/j.jml.2007.11.007 Warton, D. ., & Hui, F. K. (2011). arcsine asinine: analysis proportions ecology. Ecology, 92(1), 3-10.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Samuel Forbes. Author, maintainer. Jacob Dink. Author. Brock Ferguson. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Forbes S, Dink J, Ferguson B (2021). eyetrackingR. R package version 0.2.0, http://www.eyetracking-r.com/.","code":"@Manual{,   title = {{eyetrackingR}},   author = {Samuel Forbes and Jacob Dink and Brock Ferguson},   year = {2021},   note = {R package version 0.2.0},   url = {http://www.eyetracking-r.com/}, }"},{"path":[]},{"path":"/index.html","id":"recent-updates","dir":"","previous_headings":"","what":"Recent Updates:","title":"Eye-Tracking Data Analysis","text":"Note active development (permission) archived CRAN package eyetrackingR. archived version still available https://github.com/jwdink/eyetrackingr Warnings given latest versions dplyr ggplot2 fixed. Support plotting predictions binomial models using glmer, glmmTMB glmmPQL","code":""},{"path":"/index.html","id":"eye-tracking-data-cleaning-analysis--visualization","dir":"","previous_headings":"","what":"Eye-tracking Data: Cleaning, Analysis, & Visualization","title":"Eye-Tracking Data Analysis","text":"Samuel Forbes (samuel.h.forbes@gmail.com) Jacob Dink (jacobwdink@gmail.com) Brock Ferguson (brock.ferguson@gmail.com) package designed make dealing eye-tracking data easier. addresses tasks along pipeline raw data analysis visualization. offers several popular types analyses, including growth-curve analysis, onset-contingent reaction time analyses, well several non-parametric bootstrapping approaches. www.eyetracking-r.com","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Eye-Tracking Data Analysis","text":"install CRAN: load: development version (make sure run install.packages(\"devtools\") get devtools first):","code":"install.packages('eyetrackingR') library(eyetrackingR) devtools::install_github(\"samhforbes/eyetrackingR\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Eye-Tracking Data Analysis","text":"EyetrackingR requires data R dataframe necessary columns. reason, eyetrackingR compatible eyetracker, long can export data table import R. See preparing data vignette. data R, can prepare eyetrackingR running make_eyetrackingr_data function, e.g.: , eyetrackingR’s functionality becomes available data. Check eyetrackingR workflow get accesible overview functionality, check vignettes guides clean data, visualize , perform analyses. Copyright (c) 2021, Samuel Forbes, Jacob Dink Brock Ferguson Released MIT License (see LICENSE details)","code":"data <- make_eyetrackingr_data(your_original_data,                         participant_column = \"ParticipantName\",                        trial_column = \"Trial\",                        time_column = \"Timestamp\",                        trackloss_column = \"TrackLoss\",                        treat_non_aoi_looks_as_missing = TRUE )"},{"path":"/reference/add_aoi.html","id":null,"dir":"Reference","previous_headings":"","what":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","title":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","text":"Eyetracking-R requires column area--interest, specifying whether gaze  within area sample. function creates AOI column needed.","code":""},{"path":"/reference/add_aoi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","text":"","code":"add_aoi(   data,   aoi_dataframe,   x_col,   y_col,   aoi_name,   x_min_col = \"L\",   x_max_col = \"R\",   y_min_col = \"T\",   y_max_col = \"B\" )"},{"path":"/reference/add_aoi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","text":"data data aoi_dataframe dataframe specifying bounding-box AOI x_col, y_col column names x y coordinates dataset? aoi_name name AOI? x_min_col, x_max_col column names left right edge AOI-bounding box? Default \"L\",\"R\" y_min_col, y_max_col column names top bottom edge AOI-bounding box? Default \"T\",\"B\"","code":""},{"path":"/reference/add_aoi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","text":"Dataset new column indicating whether gaze AOI","code":""},{"path":"/reference/add_aoi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add an area-of-interest to your dataset, based on x-y coordinates and the AOI rectangle. — add_aoi","text":"Many eyetracking software packages export data column corresponding AOI; however, software , define revise AOIs running experiment, function add necessary AOI columns . function takes two dataframes: (1) original data, (2) dataframe specifying bounding box AOI. latter can specify different bounding box trial, subject, image, even video-frame-- anything like. two dataframes simply joined matching columns common (case sensitive!), unique AOI \"Trial\" aoi_dataframe, \"Trial\" column data dataframe, unique AOI coordinates trial used.","code":""},{"path":"/reference/analyze_boot_splines.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"Deprecated. Performing analysis done calling analyze_time_bins(test=\"boot_splines\").","code":""},{"path":"/reference/analyze_boot_splines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"","code":"analyze_boot_splines(data)  # S3 method for boot_splines_data analyze_boot_splines(data)"},{"path":"/reference/analyze_boot_splines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"data output boot_splines_data function","code":""},{"path":"/reference/analyze_boot_splines.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"dataframe indicating means CIs time-bin","code":""},{"path":"/reference/analyze_boot_splines.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"Estimates confidence interval difference means (within- -subjects) boot_splines_data. Confidence intervals derived alpha argument  boot_splines_data (e.g., alpha = .05, CI=(.025,.975); alpha=.01, CI=(.005,.0995))","code":""},{"path":"/reference/analyze_boot_splines.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"boot_splines_data:","code":""},{"path":"/reference/analyze_boot_splines.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate confidence intervals for bootstrapped splines data — analyze_boot_splines","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500, window_end_time = 21000,                                      rezero = FALSE) response_time <- make_time_sequence_data(response_window, time_bin_size = 500, aois = \"Animate\",                                           predictor_columns = \"Sex\",                                           summarize_by = \"ParticipantName\")                                           # bootstrap resample 500 smoothed splines from the dataset, # comparing females versus females at an alpha of .05                                          df_bootstrapped <- make_boot_splines_data(response_time,                                           predictor_column = 'Sex',                                           within_subj = FALSE,                                           bs_samples = 500,                                           alpha = .05,                                           smoother = \"smooth.spline\")  # analyze the divergences that occurred boot_splines_analysis <- analyze_boot_splines(df_bootstrapped) summary(boot_splines_analysis) }"},{"path":"/reference/analyze_time_bins.html","id":null,"dir":"Reference","previous_headings":"","what":"analyze_time_bins() — analyze_time_bins","title":"analyze_time_bins() — analyze_time_bins","text":"Runs test time-bin time_sequence_data. Supports t.test, wilcox.test, (g)lm, (g)lmer. Also includes support \"bootstrapped-splines\" test (see ?make_boot_splines_data  divergence vignette info).  default, function uses 'proportion-looking' (Prop) DV, can changed manually specifying formula. Results can plotted see test-results parameters estimates vary time. P-values can adjusted multiple comparisons p_adjust_method.","code":""},{"path":"/reference/analyze_time_bins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"analyze_time_bins() — analyze_time_bins","text":"","code":"analyze_time_bins(data, ...)  # S3 method for time_sequence_data analyze_time_bins(   data,   predictor_column,   test,   threshold = NULL,   alpha = NULL,   aoi = NULL,   formula = NULL,   treatment_level = NULL,   p_adjust_method = \"none\",   quiet = FALSE,   ... )"},{"path":"/reference/analyze_time_bins.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"analyze_time_bins() — analyze_time_bins","text":"data output 'make_time_sequence_data' function ... arguments passed selected 'test' function (e.g., paired, var.equal, etc.) predictor_column variable whose test statistic interested .  interested predictor, intercept, can enter \"intercept\" argument. Interaction terms currently supported. test type test performed time bin? Supports    t.test, wilcox.test, (g)lm, (g)lmer. Also includes support \"bootstrapped-splines\" test (see ?make_boot_splines_data  divergence vignette info). threshold Value statistic used determining significance alpha Alpha value determining significance, ignored threshold given aoi AOI analyzed? specified (dataframe multiple AOIs),  AOI predictor/covariate model (`formula` needs  specified). formula formula used test? Optional (g)lmer, unset use Prop ~ [predictor_column]. Change want use custom DV. treatment_level predictor factor, regression functions like `lm` `lmer` default  treatment-code . One option sum-code predictor entering  function. Another use `treatment_level` argument, specifies  level predictor. example, testing model `Target` predictor,  two levels, 'Animate' 'Inanimate'. R code 'Animate' reference  level, code 'Inanimate' treatment level. therefore want set  `treatment_level = Inanimate`. p_adjust_method Method adjust p.values multiple corrections (default=\"none\").  See p.adjust.methods. quiet messages progress bars suppressed? Default show","code":""},{"path":"/reference/analyze_time_bins.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"analyze_time_bins() — analyze_time_bins","text":"dataframe indicating results test time-bin.","code":""},{"path":"/reference/analyze_time_bins.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"analyze_time_bins() — analyze_time_bins","text":"time_sequence_data:","code":""},{"path":"/reference/analyze_time_bins.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"analyze_time_bins() — analyze_time_bins","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_time <- make_time_sequence_data(data, time_bin_size = 250,                                           predictor_columns = c(\"MCDI_Total\"),                                          aois = \"Animate\", summarize_by = \"ParticipantName\") tb_analysis <- analyze_time_bins(response_time, predictor_column = \"MCDI_Total\",                                   test = \"lm\", threshold = 2) summary(tb_analysis) }"},{"path":"/reference/analyze_time_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap analysis of time-clusters. — analyze_time_clusters","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"Takes data whose time bins clustered test-statistic (using make_time_cluster_data function) performs permutation test (Maris & Oostenveld, 2007). analysis takes summed statistic cluster, compares \"null\" distribution sum statistics obtained shuffling/resampling data extracting largest cluster resample.","code":""},{"path":"/reference/analyze_time_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"","code":"analyze_time_clusters(data, ...)  # S3 method for time_cluster_data analyze_time_clusters(   data,   within_subj,   samples = 2000,   formula = NULL,   shuffle_by = NULL,   parallel = FALSE,   quiet = FALSE,   ... )"},{"path":"/reference/analyze_time_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"data output make_time_cluster_data function ... args selected 'test' function; identical passed make_time_cluster_data function within_subj Logical indicating whether perform within-subjects bootstrap resampling. samples many iterations performed bootstrap resampling procedure? formula Formula test. identical passed make_time_cluster_data fxn (arg ignored , can ignored ) shuffle_by Along attribute data resampled? Default predictor column. predictor_column numeric ** within-subjects, observations  predictor value nevertheless correspond distinct conditions/categories shuffled separately. example, using vocabulary scores predict looking behavior, participant might get identical vocab scores verbs nouns; nevertheless distinct categories re-assigned separately bootstrap-resampling data. 'shuffle_by' argument allows specify column indicates kinds distinct categories resampled separately-- needed specified numeric ** within-subjects predictor column. parallel Use foreach speed boost? default . May work Windows. quiet Display progress bar/messages? progress bar parallel=TRUE.","code":""},{"path":"/reference/analyze_time_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"cluster-analysis object, can plotted summarized examine temporal periods   show significant effect predictor variable","code":""},{"path":"/reference/analyze_time_clusters.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"time_cluster_data:","code":""},{"path":"/reference/analyze_time_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap analysis of time-clusters. — analyze_time_clusters","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500, window_end_time = 21000,                                      rezero = FALSE) response_time <- make_time_sequence_data(response_window, time_bin_size = 500, aois = \"Animate\",                                           predictor_columns = \"Sex\")  time_cluster_data <- make_time_cluster_data(data = response_time, predictor_column = \"SexM\",                           aoi = \"Animate\", test = \"lmer\",                           threshold = 1.5,                           formula = LogitAdjusted ~ Sex + (1|Trial) + (1|ParticipantName)) summary(time_cluster_data) plot(time_cluster_data)  # analyze time clusters in a non-parametric analysis  tc_analysis <- analyze_time_clusters(time_cluster_data, within_subj = FALSE,                                      samples = 2000) plot(tc_analysis) summary(tc_analysis) }"},{"path":"/reference/clean_by_trackloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","title":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","text":"Remove trials/participants much trackloss, customizable threshold.","code":""},{"path":"/reference/clean_by_trackloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","text":"","code":"clean_by_trackloss(   data,   participant_prop_thresh = 1,   trial_prop_thresh = 1,   window_start_time = -Inf,   window_end_time = Inf )"},{"path":"/reference/clean_by_trackloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","text":"data Data already run make_eyetrackingr_data participant_prop_thresh Maximum proportion trackloss participants trial_prop_thresh Maximum proportion trackloss trials window_start_time, window_end_time Time-window within want trackloss analysis based. Allows keep entire trial window data, clean based trackloss within subset ","code":""},{"path":"/reference/clean_by_trackloss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","text":"Cleaned data","code":""},{"path":"/reference/clean_by_trackloss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean data by removing high-trackloss trials/subjects. — clean_by_trackloss","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )  # scrub all trials with greater than 25% trackloss, and all # participants with greater than 25% trackloss on average # during the timeperiod 15500-2100 data_clean <- clean_by_trackloss(data,                                  participant_prop_thresh = .25,                                   trial_prop_thresh = .25,                                  window_start_time = 15500,                                   window_end_time = 21000 ) #> Performing Trackloss Analysis... #> Will exclude trials whose trackloss proportion is greater than : 0.25 #> \t...removed  33  trials. #> Will exclude participants whose trackloss proportion is greater than : 0.25 #> \t...removed  3  participants.  # scrub all trials with greater than 25% trackloss, but leave participants with a high average data_clean <- clean_by_trackloss(data,                                  trial_prop_thresh = .25,                                  window_start_time = 15500,                                   window_end_time = 21000 ) #> Performing Trackloss Analysis... #> Will exclude trials whose trackloss proportion is greater than : 0.25 #> \t...removed  33  trials."},{"path":"/reference/describe_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Describe dataset — describe_data","title":"Describe dataset — describe_data","text":"Returns descriptive statistics column choice. simple convenience function wraps dplyr::group_by dplyr::summarize, allowing quick glance data.","code":""},{"path":"/reference/describe_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Describe dataset — describe_data","text":"","code":"describe_data(   data,   describe_column,   group_columns,   quantiles = c(0.025, 0.975) )"},{"path":"/reference/describe_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Describe dataset — describe_data","text":"data Data already run make_eyetrackingr_data describe_column column return descriptive statistics . group_columns columns group calculating descriptive statistics (e.g., participants, conditions, etc.) quantiles Numeric vector length two quantiles compute (default: c(.025, .975)).","code":""},{"path":"/reference/describe_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Describe dataset — describe_data","text":"dataframe giving descriptive statistics describe_column, including mean, SD, var, min, max, number trials","code":""},{"path":"/reference/describe_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Describe dataset — describe_data","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) describe_data(data, describe_column = \"Animate\", group_columns = \"ParticipantName\") #> # A tibble: 28 × 9 #>    ParticipantName  Mean    SD LowerQ UpperQ   Min   Max     N NumTrials #>    <fct>           <dbl> <dbl>  <dbl>  <dbl> <int> <int> <int>     <int> #>  1 ANCAT139        0.397 0.490      0      1     0     1  1262         1 #>  2 ANCAT18         0.626 0.484      0      1     0     1  7583         6 #>  3 ANCAT22         0.434 0.496      0      1     0     1  6314         5 #>  4 ANCAT23         0.791 0.407      0      1     0     1  7582         6 #>  5 ANCAT26         0.648 0.478      0      1     0     1  7586         6 #>  6 ANCAT39         0.699 0.459      0      1     0     1  7582         6 #>  7 ANCAT45         0.543 0.498      0      1     0     1  7579         6 #>  8 ANCAT50         0.785 0.411      0      1     0     1  7579         6 #>  9 ANCAT53         0.527 0.499      0      1     0     1  6322         5 #> 10 ANCAT55         0.652 0.476      0      1     0     1  7578         6 #> # … with 18 more rows"},{"path":"/reference/eyetrackingR.html","id":null,"dir":"Reference","previous_headings":"","what":"eyetrackingR: A package for cleaning, analyzing, and visualizing eye-tracking datasets — eyetrackingR","title":"eyetrackingR: A package for cleaning, analyzing, and visualizing eye-tracking datasets — eyetrackingR","text":"package addresses tasks along pipeline raw eye-tracking data analysis visualization. offers several popular types analyses, including linear growth curve time analyses, onset-contingent reaction time analyses, cluster mass analyses, well novel non-parametric approaches time-series data.","code":""},{"path":"/reference/eyetrackingR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"eyetrackingR: A package for cleaning, analyzing, and visualizing eye-tracking datasets — eyetrackingR","text":"information tutorials, visit http://www.eyetracking-r.com/.","code":""},{"path":"/reference/get_time_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Get information about the clusters in a cluster-analysis — get_time_clusters","title":"Get information about the clusters in a cluster-analysis — get_time_clusters","text":"Get information clusters cluster-analysis","code":""},{"path":"/reference/get_time_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get information about the clusters in a cluster-analysis — get_time_clusters","text":"","code":"get_time_clusters(object)  # S3 method for time_cluster_data get_time_clusters(object)  # S3 method for cluster_analysis get_time_clusters(object)"},{"path":"/reference/get_time_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get information about the clusters in a cluster-analysis — get_time_clusters","text":"object output analyze_time_clusters function","code":""},{"path":"/reference/get_time_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get information about the clusters in a cluster-analysis — get_time_clusters","text":"dataframe information clusters","code":""},{"path":"/reference/get_time_clusters.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Get information about the clusters in a cluster-analysis — get_time_clusters","text":"time_cluster_data: Get time clusters dataframe cluster_analysis: Get time clusters dataframe","code":""},{"path":"/reference/make_boot_splines_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap resample splines for time-series data. — make_boot_splines_data","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"Deprecated. Performing analysis done calling analyze_time_bins(test=\"boot_splines\").","code":""},{"path":"/reference/make_boot_splines_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"","code":"make_boot_splines_data(   data,   predictor_column,   within_subj,   aoi,   bs_samples,   smoother,   resolution,   alpha,   ... )  # S3 method for time_sequence_data make_boot_splines_data(   data,   predictor_column,   within_subj,   aoi = NULL,   bs_samples = 1000,   smoother = \"smooth.spline\",   resolution = NULL,   alpha = 0.05,   ... )"},{"path":"/reference/make_boot_splines_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"data output time_sequence_data() predictor_column predictor var split ? Maximum two conditions within_subj two conditions within subjects? aoi AOI wish perform analysis ? bs_samples many iterations run bootstrap resampling? Default 1000 smoother Smooth data using \"smooth.spline,\" \"loess,\" \"none\" smoothing resolution resolution return predicted splines , ms? e.g., 10ms = 100 intervals per second, hundredths second. Default size time-bins. alpha p-value groups sufficiently \"diverged\" ... Ignored","code":""},{"path":"/reference/make_boot_splines_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"bootstrapped distribution samples time-bin","code":""},{"path":"/reference/make_boot_splines_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"method builds confidence intervals around proportion-looking data bootstrap resampling. Data can smoothed fitting smoothing splines. function performs bootstrap resampling, analyze_boot_splines generates confidence intervals tests divergences. Limited statistical test two conditions.","code":""},{"path":"/reference/make_boot_splines_data.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"time_sequence_data:","code":""},{"path":"/reference/make_boot_splines_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap resample splines for time-series data. — make_boot_splines_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500,                                      window_end_time = 21000, rezero = FALSE) response_time <- make_time_sequence_data(response_window, time_bin_size = 500, aois = \"Animate\",                                           predictor_columns = \"Sex\",                                           summarize_by = \"ParticipantName\")                                           df_bootstrapped <- make_boot_splines_data(response_time,                                            predictor_column = 'Sex',                                            within_subj = FALSE,                                            bs_samples = 500,                                            alpha = .05,                                           smoother = \"smooth.spline\")  }"},{"path":"/reference/make_eyetrackingr_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"first function use using eyetrackingR project (potentially exception `add_aoi`, need add AOIs). function takes raw dataframe,  well information dataframe. confirms columns right format,  based information. treat_non_aoi_looks_as_missing set TRUE,  converts non-AOI looks missing data (see \"Preparing data\" vignette  information).","code":""},{"path":"/reference/make_eyetrackingr_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"","code":"make_eyetrackingr_data(   data,   participant_column,   trackloss_column,   time_column,   trial_column,   aoi_columns,   treat_non_aoi_looks_as_missing,   item_columns = NULL )"},{"path":"/reference/make_eyetrackingr_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"data original data. See details section . participant_column Column name participant identifier trackloss_column Column name indicating trackloss time_column Column name indicating time trial_column Column name indicating trial identifier aoi_columns Names AOIs treat_non_aoi_looks_as_missing logical indicating like perform \"proportion-looking\" calculations, central eyetrackingR's eyetracking analyses. set TRUE, samples AOIs (defined aoi_columns  argument) treated missing data; comes time eyetrackingR calculate  proportion looking AOI, calculated \"time looking AOI divided  time looking AOIs.\" contrast, parameter set FALSE, proportion  looking AOI calculated \"time looking AOI divided total time  looking.\" item_columns Column names indicating items (optional)","code":""},{"path":"/reference/make_eyetrackingr_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"Dataframe ready use eyetrackingR.","code":""},{"path":"/reference/make_eyetrackingr_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"eyetrackingR designed deal data (relatively) raw form, row specifies sample. row represent equally spaced unit time (e.g., eye-tracker's sample rate 100hz, row corresponds eye-position every 10ms). contrast parsed data software bundled eye-trackers can sometimes output (e.g., already parsed saccades fixations). eyetrackingR, simplest data best. also maximizes compatibility: eyetrackingR work eye-tracker's data (e.g., Eyelink, Tobii, etc.), since requires basic format.","code":""},{"path":"/reference/make_eyetrackingr_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert raw data for use in eyetrackingR — make_eyetrackingr_data","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )"},{"path":"/reference/make_onset_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make onset-contingent data. — make_onset_data","title":"Make onset-contingent data. — make_onset_data","text":"Divide trials AOI participants started . Calculate switches away AOI, using rolling window determine length consitutes switch. Augment original data column indicating whether row switch-away sample.","code":""},{"path":"/reference/make_onset_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make onset-contingent data. — make_onset_data","text":"","code":"make_onset_data(   data,   onset_time,   fixation_window_length = NULL,   target_aoi,   distractor_aoi = NULL )"},{"path":"/reference/make_onset_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make onset-contingent data. — make_onset_data","text":"data original (verified) data onset_time check participants' \"starting\" AOI? fixation_window_length AOI currently fixated determined taking rolling average length (ms). width window rolling average. target_aoi AOI target switched ** distractor_aoi AOI distractor switched ** (default = !target_aoi)","code":""},{"path":"/reference/make_onset_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make onset-contingent data. — make_onset_data","text":"Original dataframe augmented column indicating switch away target AOI","code":""},{"path":"/reference/make_onset_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make onset-contingent data. — make_onset_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500, window_end_time = 21000,                                      rezero = FALSE) inanimate_trials <- subset(response_window, grepl('(Spoon|Bottle)', Trial)) onsets <- make_onset_data(inanimate_trials, onset_time = 15500, target_aoi='Inanimate') }"},{"path":"/reference/make_switch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize data into time-to-switch from initial AOI. — make_switch_data","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"Take trials split initial-AOI, determine quickly participants switch away AOI","code":""},{"path":"/reference/make_switch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"","code":"make_switch_data(data, predictor_columns, summarize_by)  # S3 method for onset_data make_switch_data(data, predictor_columns = NULL, summarize_by = NULL)"},{"path":"/reference/make_switch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"data output make_onset_data predictor_columns Variables/covariates interest analyzing time--switch summarize_by data summarized along, e.g., participants, items, etc.?  , give column name(s) . left blank, leave trials distinct. former  needed traditional analyses (t.tests, ANOVAs), latter preferable  mixed-effects models (lmer)","code":""},{"path":"/reference/make_switch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"dataframe indicating initial AOI time--switch AOI   trial/subject/item/etc.","code":""},{"path":"/reference/make_switch_data.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"onset_data:","code":""},{"path":"/reference/make_switch_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize data into time-to-switch from initial AOI. — make_switch_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500, window_end_time = 21000,                                      rezero = FALSE) inanimate_trials <- subset(response_window, grepl('(Spoon|Bottle)', Trial)) onsets <- make_onset_data(inanimate_trials, onset_time = 15500,                            fixation_window_length = 100, target_aoi='Inanimate')                            df_switch <- make_switch_data(onsets, predictor_columns = \"MCDI_Total\",               summarize_by = \"ParticipantName\") plot(df_switch, \"MCDI_Total\") }"},{"path":"/reference/make_time_cluster_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make data for cluster analysis. — make_time_cluster_data","title":"Make data for cluster analysis. — make_time_cluster_data","text":"Takes data summarized time-bins make_time_sequence_data(), finds adjacent time bins pass test-statistic threshold, assigns adjacent bins groups (clusters). Output ready cluster permutation-based analyses (Maris & Oostenveld, 2007). Supports t.test, wilcox.test, (g)lm, (g)lmer. Also includes support \"bootstrapped-splines\" test (see ?make_boot_splines_data  divergence vignette info).  default, function uses 'proportion-looking' (Prop) DV, can changed manually specifying formula.","code":""},{"path":"/reference/make_time_cluster_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make data for cluster analysis. — make_time_cluster_data","text":"","code":"make_time_cluster_data(data, ...)  # S3 method for time_sequence_data make_time_cluster_data(   data,   predictor_column,   aoi = NULL,   test,   threshold = NULL,   formula = NULL,   treatment_level = NULL,   ... )"},{"path":"/reference/make_time_cluster_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make data for cluster analysis. — make_time_cluster_data","text":"data output make_time_sequence_data function ... arguments passed selected 'test' function (e.g., paired, var.equal, etc.) predictor_column column name containing variable whose test statistic interested . aoi AOI analyzed? specified (dataframe multiple AOIs),  AOI predictor/covariate model (`formula` needs  specified). test type test performed time bin? Supports t.test, (g)lm, (g)lmer. Also includes experimental support \"bootstrapped-splines\" test (see ?make_boot_splines_data  divergence vignette  info). support wilcox.test. threshold Time-bins test-statistics greater amount grouped clusters. formula formula used test? Optional ((g)lmer), unset uses Prop ~ [predictor_column] treatment_level predictor factor, regression functions like `lm` `lmer` default  treatment-code . One option sum-code predictor entering  function. Another use `treatment_level` argument, specifies  level predictor. example, testing model `Target` predictor,  two levels, 'Animate' 'Inanimate'. R code 'Animate' reference  level, code 'Inanimate' treatment level. therefore want set  `treatment_level = Inanimate`.","code":""},{"path":"/reference/make_time_cluster_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make data for cluster analysis. — make_time_cluster_data","text":"original data, augmented information clusters. Calling summary data   describe clusters. dataset ready analyze_time_clusters method.","code":""},{"path":"/reference/make_time_cluster_data.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Make data for cluster analysis. — make_time_cluster_data","text":"time_sequence_data: Make data time cluster analysis","code":""},{"path":"/reference/make_time_cluster_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make data for cluster analysis. — make_time_cluster_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_window <- subset_by_window(data, window_start_time = 15500, window_end_time = 21000,                                      rezero = FALSE)  # identify clusters in the sequence data using a t-test with # threshold t-value of 2  # (note: t-tests require a summarized dataset) response_time <- make_time_sequence_data(response_window, time_bin_size = 500, aois = \"Animate\",                                           predictor_columns = \"Sex\",                                          summarize_by = \"ParticipantName\")                                           time_cluster_data <- make_time_cluster_data(data = response_time,                                             predictor_column = \"Sex\",                                             aoi = \"Animate\",                                             test = \"t.test\",                                             threshold = 2 )  # identify clusters in the sequence data using an lmer() random-effects # model with a threshold t-value of 1.5.  # random-effects models don't require us to summarize response_time <- make_time_sequence_data(response_window, time_bin_size = 500, aois = \"Animate\",                                           predictor_columns = \"Sex\")     # but they do require a formula to be specified time_cluster_data <- make_time_cluster_data(data = response_time,                            predictor_column = \"SexM\",                            aoi = \"Animate\",                            test = \"lmer\",                            threshold = 1.5,                            formula = LogitAdjusted ~ Sex + (1|Trial) + (1|ParticipantName) ) }"},{"path":"/reference/make_time_sequence_data.html","id":null,"dir":"Reference","previous_headings":"","what":"make_time_sequence_data() — make_time_sequence_data","title":"make_time_sequence_data() — make_time_sequence_data","text":"Creates time-bins summarizes proportion-looking within time-bin.","code":""},{"path":"/reference/make_time_sequence_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_time_sequence_data() — make_time_sequence_data","text":"","code":"make_time_sequence_data(   data,   time_bin_size,   aois = NULL,   predictor_columns = NULL,   other_dv_columns = NULL,   summarize_by = NULL )"},{"path":"/reference/make_time_sequence_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_time_sequence_data() — make_time_sequence_data","text":"data output make_eyetrackingr_data time_bin_size large time bin ? Units whatever units time column aois AOI(s) /interest? Defaults specified make_eyetracking_r_data predictor_columns columns indicate predictor variables, therefore preserved grouping operations? other_dv_columns Within time-bin, function calculate proportion- looking, also mean columns specified . summarize_by data summarized along, e.g., participants, items, etc.? , give column name(s) . left blank, leave trials distinct. former needed traditional analyses (t.test, ANOVA), latter preferable mixed-effects models (lmer)","code":""},{"path":"/reference/make_time_sequence_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_time_sequence_data() — make_time_sequence_data","text":"Data binned time-bins, proportion-looking transformations well orthogonal   time-polynomials growth curve analysis","code":""},{"path":"/reference/make_time_sequence_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"make_time_sequence_data() — make_time_sequence_data","text":"Aside proportion looking (Prop), function returns several columns useful subsequent analysis: LogitAdjusted - logit defined log( Prop / (1 - Prop) ).  transformation attempts map bounded 0,1 data real number line. Unfortunately,  data exactly 0 1, undefined. One solution add small value  datapoints equal 0, subtract small value datapoints equal 1 (use  1/2 smallest nonzero value adjustment). Elog - Another way calculating corrected logit transformation add small value epsilon numerator denominator logit equation (use 0.5). Weights - attempt correct Elog transformation, since  variance logit depends mean. can used mixed effects model setting  weights=Weights lmer (note reciprocal weights calculated empirical logit walkthrough, ** set weights = 1/Weights done .) ArcSin - arcsine-root transformation raw proportions, defined asin(sqrt(Prop)) ot - columns (ot1-ot7) represent (centered) orthogonal time polynomials,  needed growth curve analysis. See  vignette growth curve  models details.","code":""},{"path":"/reference/make_time_sequence_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_time_sequence_data() — make_time_sequence_data","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )  # bin data in 250ms bins, and generate a dataframe # with a single AOI (Animate) predicted by Sex, and summarized by ParticipantName response_time <- make_time_sequence_data(data,                                          time_bin_size = 250,                                          predictor_columns = c(\"Sex\"),                                          aois = \"Animate\",                                          summarize_by = \"ParticipantName\" )  # optionally specify other columns in the data # to be included in the generated dataframe # (e.g., for use in statistical models) # bin data in 250ms bins, and generate a dataframe # with Animate and MCDI_Total summarized by ParticipantName response_time <- make_time_sequence_data(data,                                          time_bin_size = 250,                                          predictor_columns = c(\"Sex\",\"MCDI_Total\"),                                          aois = \"Animate\",                                           summarize_by = \"ParticipantName\" )"},{"path":"/reference/make_time_window_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a dataset collapsing over a time-window — make_time_window_data","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"Collapse time across entire window return dataframe ready analyses","code":""},{"path":"/reference/make_time_window_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"","code":"make_time_window_data(   data,   aois = NULL,   predictor_columns = NULL,   other_dv_columns = NULL,   summarize_by = NULL )"},{"path":"/reference/make_time_window_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"data output make_eyetrackingr_data aois AOI(s) /interest? Defaults specified make_eyetracking_r_data predictor_columns columns indicate predictor vars, therefore preserved grouping operations? other_dv_columns Within participant/trial (whatever specified summarize_by),  function calculate proportion-looking, also mean columns specified . summarize_by data summarized along, e.g., participants, items, etc.? , give column names . left blank, leave trials distinct. former needed traditional analyses (t.test, ANOVA), latter preferable mixed-effects models (lmer)","code":""},{"path":"/reference/make_time_window_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"Data proportion-looking transformations (logit, arc-sin, etc.)","code":""},{"path":"/reference/make_time_window_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"Aside proportion looking (Prop), function returns several columns useful subsequent analysis: LogitAdjusted - logit defined log( Prop / (1 - Prop) ).  transformation attempts map bounded 0,1 data real number line. Unfortunately,  data exactly 0 1, undefined. One solution add small value  datapoints equal 0, subtract small value datapoints equal 1 (use  1/2 smallest nonzero value adjustment). Elog - Another way calculating corrected logit transformation add small value epsilon numerator denominator logit equation (use 0.5). Weights - attempt correct Elog transformation, since  variance logit depends mean. can used mixed effects model setting  weights=Weights lmer (note reciprocal weights calculated empirical logit walkthrough, ** set weights = 1/Weights done .) ArcSin - arcsine-root transformation raw proportions, defined asin(sqrt(Prop))","code":""},{"path":"/reference/make_time_window_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a dataset collapsing over a time-window — make_time_window_data","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )  # generate a dataset summarizing an AOI (Animate) by ParticipantName response_window_agg_by_sub <- make_time_window_data(data,                                                     aois='Animate',                                                     summarize_by = \"ParticipantName\" )  if (FALSE) { # optionally included additional columns for use as predictors # in later statistical models response_window_agg_by_sub <- make_time_window_data(data,                                                     aois='Animate',                                                     predictor_columns=c('Age','MCDI_Total'),                                                     summarize_by = \"ParticipantName\" )  # plot the aggregated data for sanity check plot(response_window_agg_by_sub, predictor_columns=\"Age\", dv = \"LogitAdjusted\")  }"},{"path":"/reference/plot.bin_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot test-statistic for each time-bin in a time-series — plot.bin_analysis","title":"Plot test-statistic for each time-bin in a time-series — plot.bin_analysis","text":"Plot result analyze_time_bins function, statistic threshold bin","code":""},{"path":"/reference/plot.bin_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot test-statistic for each time-bin in a time-series — plot.bin_analysis","text":"","code":"# S3 method for bin_analysis plot(x, type = NULL, ...)"},{"path":"/reference/plot.bin_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot test-statistic for each time-bin in a time-series — plot.bin_analysis","text":"x output analyze_time_bins type function can plot test-statistic (\"statistic\"), parameter estimate +/- std. error (\"estimate\"), p-value (\"pvalue\") negative-log-pvalue (\"neg_log_pvalue\"). test gives critical-statistic, default plot test-statistic. Otherwise, default plot estimate. wilcox, p-values can plotted. ... Ignored","code":""},{"path":"/reference/plot.bin_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot test-statistic for each time-bin in a time-series — plot.bin_analysis","text":"ggplot object","code":""},{"path":"/reference/plot.boot_splines_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot differences in bootstrapped-splines data — plot.boot_splines_analysis","title":"Plot differences in bootstrapped-splines data — plot.boot_splines_analysis","text":"Plot means CIs bootstrapped spline difference estimates intervals (either within-subjects -subjects)","code":""},{"path":"/reference/plot.boot_splines_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot differences in bootstrapped-splines data — plot.boot_splines_analysis","text":"","code":"# S3 method for boot_splines_analysis plot(x, ...)"},{"path":"/reference/plot.boot_splines_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot differences in bootstrapped-splines data — plot.boot_splines_analysis","text":"x output analyze_boot_splines function ... Ignored","code":""},{"path":"/reference/plot.boot_splines_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot differences in bootstrapped-splines data — plot.boot_splines_analysis","text":"ggplot object","code":""},{"path":"/reference/plot.boot_splines_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bootstrapped-splines data — plot.boot_splines_data","title":"Plot bootstrapped-splines data — plot.boot_splines_data","text":"Plot means CIs bootstrapped splines (either within-subjects -subjects)","code":""},{"path":"/reference/plot.boot_splines_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bootstrapped-splines data — plot.boot_splines_data","text":"","code":"# S3 method for boot_splines_data plot(x, ...)"},{"path":"/reference/plot.boot_splines_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bootstrapped-splines data — plot.boot_splines_data","text":"x output make_boot_splines_data function ... Ignored","code":""},{"path":"/reference/plot.boot_splines_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bootstrapped-splines data — plot.boot_splines_data","text":"ggplot object","code":""},{"path":"/reference/plot.cluster_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the results of a cluster analysis. — plot.cluster_analysis","title":"Visualize the results of a cluster analysis. — plot.cluster_analysis","text":"Plots result bootstrapping cluster analysis. histogram sum statistics shuffled (null) distribution, sum statisics clusters indicated dashed lines.","code":""},{"path":"/reference/plot.cluster_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the results of a cluster analysis. — plot.cluster_analysis","text":"","code":"# S3 method for cluster_analysis plot(x, ...)"},{"path":"/reference/plot.cluster_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the results of a cluster analysis. — plot.cluster_analysis","text":"x object returned cluster_analysis() ... Ignored","code":""},{"path":"/reference/plot.cluster_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the results of a cluster analysis. — plot.cluster_analysis","text":"ggplot object","code":""},{"path":"/reference/plot.eyetrackingR_data_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot some summarized data from eyetrackingR — plot.eyetrackingR_data_summary","title":"Plot some summarized data from eyetrackingR — plot.eyetrackingR_data_summary","text":"Plots data returned describe_data. Like function, convenient  wrapper good sanity checks.","code":""},{"path":"/reference/plot.eyetrackingR_data_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot some summarized data from eyetrackingR — plot.eyetrackingR_data_summary","text":"","code":"# S3 method for eyetrackingR_data_summary plot(x, ...)"},{"path":"/reference/plot.eyetrackingR_data_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot some summarized data from eyetrackingR — plot.eyetrackingR_data_summary","text":"x data returned make_time_window_data() ... Ignored","code":""},{"path":"/reference/plot.eyetrackingR_data_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot some summarized data from eyetrackingR — plot.eyetrackingR_data_summary","text":"ggplot object","code":""},{"path":"/reference/plot.onset_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot onset-contingent data — plot.onset_data","title":"Plot onset-contingent data — plot.onset_data","text":"Divide trials AOI participants started ; plot proportion looking away AOI.","code":""},{"path":"/reference/plot.onset_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot onset-contingent data — plot.onset_data","text":"","code":"# S3 method for onset_data plot(x, predictor_columns = NULL, ...)"},{"path":"/reference/plot.onset_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot onset-contingent data — plot.onset_data","text":"x output make_onset_data function predictor_columns Column(s) facet data. Maximum two columns. perform median split numeric. ... Ignored","code":""},{"path":"/reference/plot.onset_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot onset-contingent data — plot.onset_data","text":"ggplot object","code":""},{"path":"/reference/plot.switch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot mean switch-from-initial-AOI times. — plot.switch_data","title":"Plot mean switch-from-initial-AOI times. — plot.switch_data","text":"Boxplot mean switch time aggregated subjects within FirstAOI, potentially faceted predictor_columns.","code":""},{"path":"/reference/plot.switch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot mean switch-from-initial-AOI times. — plot.switch_data","text":"","code":"# S3 method for switch_data plot(x, predictor_columns = NULL, ...)"},{"path":"/reference/plot.switch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot mean switch-from-initial-AOI times. — plot.switch_data","text":"x output make_switch_data function predictor_columns Column(s) facet data. Maximum two columns. perform median split numeric. ... Ignored","code":""},{"path":"/reference/plot.switch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot mean switch-from-initial-AOI times. — plot.switch_data","text":"ggplot object","code":""},{"path":"/reference/plot.time_cluster_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot test-statistic for each time-bin in a time-series, highlight clusters.\nPlot time_cluster_data, highlights clusters of above-threshold time-bins. — plot.time_cluster_data","title":"Plot test-statistic for each time-bin in a time-series, highlight clusters.\nPlot time_cluster_data, highlights clusters of above-threshold time-bins. — plot.time_cluster_data","text":"Plot test-statistic time-bin time-series, highlight clusters. Plot time_cluster_data, highlights clusters -threshold time-bins.","code":""},{"path":"/reference/plot.time_cluster_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot test-statistic for each time-bin in a time-series, highlight clusters.\nPlot time_cluster_data, highlights clusters of above-threshold time-bins. — plot.time_cluster_data","text":"","code":"# S3 method for time_cluster_data plot(x, type = NULL, ...)"},{"path":"/reference/plot.time_cluster_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot test-statistic for each time-bin in a time-series, highlight clusters.\nPlot time_cluster_data, highlights clusters of above-threshold time-bins. — plot.time_cluster_data","text":"x output make_time_cluster_data type function can plot test-statistic (\"statistic\"), parameter estimate +/- std. error (\"estimate\"), p-value (\"pvalue\") negative-log-pvalue (\"neg_log_pvalue\"). test gives critical-statistic, default plot test-statistic. Otherwise, default plot estimate. wilcox, p-values can plotted; boot-splines, p-values  plotted. ... Ignored","code":""},{"path":"/reference/plot.time_cluster_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot test-statistic for each time-bin in a time-series, highlight clusters.\nPlot time_cluster_data, highlights clusters of above-threshold time-bins. — plot.time_cluster_data","text":"ggplot object","code":""},{"path":"/reference/plot.time_sequence_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot time-sequence data — plot.time_sequence_data","title":"Plot time-sequence data — plot.time_sequence_data","text":"Plot timecourse looking. AOI plotted separate pane, data can  split groups predictor column. Data collapsed subject plotting. Supports overlaying predictions growth-curve mixed effects model data","code":""},{"path":"/reference/plot.time_sequence_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot time-sequence data — plot.time_sequence_data","text":"","code":"# S3 method for time_sequence_data plot(x, predictor_column = NULL, dv = \"Prop\", model = NULL, ...)"},{"path":"/reference/plot.time_sequence_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot time-sequence data — plot.time_sequence_data","text":"x data make_time_sequence_data. collapsed subject plotting (unless already collapsed factor). predictor_column Data can grouped predictor column (median split performed numeric) dv measure gaze want use? (Prop, Elog, ArcSin) model (Optional) growth-curve mixed effects model (lmer) used time_sequence_data. model given, function overlay predictions model data ... Ignored","code":""},{"path":"/reference/plot.time_sequence_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot time-sequence data — plot.time_sequence_data","text":"ggplot object","code":""},{"path":"/reference/plot.time_sequence_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot time-sequence data — plot.time_sequence_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE ) response_time <- make_time_sequence_data(data, time_bin_size = 250,                                           predictor_columns = c(\"MCDI_Total\"),                                          aois = \"Animate\", summarize_by = \"ParticipantName\")  # visualize time results plot(response_time, predictor_column = \"MCDI_Total\")  }"},{"path":"/reference/plot.time_window_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a time-window dataset — plot.time_window_data","title":"Plot a time-window dataset — plot.time_window_data","text":"Plots data returned make_time_window_data. Data can mapped onto (two) predictor columns. predictor columns supplied, AOI placed x-axis; otherwise, data AOI set separate facet.","code":""},{"path":"/reference/plot.time_window_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a time-window dataset — plot.time_window_data","text":"","code":"# S3 method for time_window_data plot(x, predictor_columns = NULL, dv = \"Prop\", ...)"},{"path":"/reference/plot.time_window_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a time-window dataset — plot.time_window_data","text":"x data returned make_time_window_data() predictor_columns two columns indicating predictors. first maps X-axis, second group/color. latter numeric, median split performed. dv dv used plotting? Raw proportion-looking (\"Prop\"), empirical logit (\"Elog\"), \"ArcSin\"? ... Ignored","code":""},{"path":"/reference/plot.time_window_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a time-window dataset — plot.time_window_data","text":"ggplot object","code":""},{"path":"/reference/plot.time_window_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a time-window dataset — plot.time_window_data","text":"Data collapsed -participants plotting.","code":""},{"path":"/reference/plot.time_window_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a time-window dataset — plot.time_window_data","text":"","code":"if (FALSE) { data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE) response_window_agg_by_sub <- make_time_window_data(data,                                                      aois='Animate',                                                     predictor_columns=c('Age','MCDI_Total'))                                                      plot(response_window_agg_by_sub, predictor_columns=\"Age\", dv = \"LogitAdjusted\")  }"},{"path":"/reference/print.cluster_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for Cluster Analysis — print.cluster_analysis","title":"Print Method for Cluster Analysis — print.cluster_analysis","text":"Print Method Cluster Analysis","code":""},{"path":"/reference/print.cluster_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for Cluster Analysis — print.cluster_analysis","text":"","code":"# S3 method for cluster_analysis print(x, ...)"},{"path":"/reference/print.cluster_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for Cluster Analysis — print.cluster_analysis","text":"x output analyze_clusters function ... Ignored","code":""},{"path":"/reference/print.cluster_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for Cluster Analysis — print.cluster_analysis","text":"Prints information bootstrapped null distribution, well information cluster.","code":""},{"path":"/reference/reclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Add the original class/attributes back onto result (usually of dplyr operation) — reclass","title":"Add the original class/attributes back onto result (usually of dplyr operation) — reclass","text":"Add original class/attributes back onto result (usually dplyr operation)","code":""},{"path":"/reference/reclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add the original class/attributes back onto result (usually of dplyr operation) — reclass","text":"","code":"reclass(x, result, ...)"},{"path":"/reference/reclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add the original class/attributes back onto result (usually of dplyr operation) — reclass","text":"x original object, class inforamation want restore. result transformation x, may removed class/attributes. ... Ignored","code":""},{"path":"/reference/reclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add the original class/attributes back onto result (usually of dplyr operation) — reclass","text":"result, now class/attribute information restored.","code":""},{"path":"/reference/simulate_eyetrackingr_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate an eyetrackingR dataset — simulate_eyetrackingr_data","title":"Simulate an eyetrackingR dataset — simulate_eyetrackingr_data","text":"function creates eyetrackingR dataset (.e., already run make_eyetrackingr_data). can helpful examining false-alarm sensitivity analysis-techniques via  simulations.","code":""},{"path":"/reference/simulate_eyetrackingr_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate an eyetrackingR dataset — simulate_eyetrackingr_data","text":"","code":"simulate_eyetrackingr_data(   num_participants = 16,   num_items_per_condition = 6,   trial_length = 5000,   pref = 0.5,   pref_window = c(1, trial_length),   noisy_window = NULL,   ... )"},{"path":"/reference/simulate_eyetrackingr_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate an eyetrackingR dataset — simulate_eyetrackingr_data","text":"num_participants Number participants num_items_per_condition Number trials per-subject per-condition. trial_length long trial (ms)? pref preference two AOIs \"high\" condition,  1 100 preference). \"low\" condition, preference two AOIs equal, default effect condition. pref_window Vector length two, specifying start end time-window participants expressed preference specified pref. Default entire trial noisy_window Vector length two, specifying start end time-window substantial trackloss trial. ... Ignored","code":""},{"path":"/reference/simulate_eyetrackingr_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate an eyetrackingR dataset — simulate_eyetrackingr_data","text":"Dataframe eye-tracking data","code":""},{"path":"/reference/subset_by_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"One annoying aspects preparing raw eyetracking data filtering data relevant window within trial, since many experiments precise start end time window can vary  trial trial. function allows several approaches subsetting data relevant time- window-- see 'Details' .","code":""},{"path":"/reference/subset_by_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"","code":"subset_by_window(   data,   rezero = TRUE,   remove = TRUE,   window_start_msg = NULL,   window_end_msg = NULL,   msg_col = NULL,   window_start_col = NULL,   window_end_col = NULL,   window_start_time = NULL,   window_end_time = NULL,   quiet = FALSE )"},{"path":"/reference/subset_by_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"data original dataset rezero beginning window considered zero point timestamp? Default TRUE remove everything beginning end window removed?  Default TRUE. set FALSE rezero set FALSE, error thrown (since case, function anything). window_start_msg method (1). message present row whose time corresponds  trial start time. Common eyetrackers send message trial/stimuli start. window_end_msg method (1). message present row whose time corresponds  trial end time. Common eyetrackers send message trial-end/keypress/lookaway/etc. msg_col method (1). indicating trial start/end message column, name column. window_start_col method (2). column gives start time trial. window_end_col method (2). column gives end time trial. window_start_time method (3). Number indicating start time applies trials. window_end_time method (3). Number indicating end time applies trials. quiet Suppress messages? Default FALSE","code":""},{"path":"/reference/subset_by_window.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"Subsetted data","code":""},{"path":"/reference/subset_by_window.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"trial start/end times can indicated message sent (e.g., TRIAL_START)  particular row trial. case, timestamp row used. trial start/end times can indicated column specifies trial start/end times trial. trial start/end times can indicated actual start stop time, across trials (simplest case). start time end time need adjusting, leave end time argument blank; vice versa. function can either rezero data (trial start time select new zero-time-point),  . former useful performing initial data-cleaning (e.g., different trial-starts  trial, indicated message), latter useful want \"zoom \" particular  portion data keeping obvious fact parts trial (e.g.,  image always appears 5000ms-7000ms trial, one analysis interested  portion).","code":""},{"path":"/reference/subset_by_window.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract a subset of the dataset within a time-window in each trial. — subset_by_window","text":"","code":"data(\"word_recognition\") data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )  # zoom in to 15500-21000ms response_window <- subset_by_window(data,                                     window_start_time = 15500,                                     window_end_time = 21000, rezero = FALSE, remove = TRUE) #> Avg. window length in new data will be 5500  # zoom in to 15500-21000ms and re-zero so timestamps start at 0 response_window <- subset_by_window(data,                                     window_start_time = 15500,                                      window_end_time = 21000,                                      rezero = TRUE,                                      remove = TRUE) #> Avg. window length in new data will be 5500  # keep all data, but re-zero it response_window <- subset_by_window(data,                                     window_start_time = 0,                                      rezero = TRUE,                                      remove = FALSE)"},{"path":"/reference/summary.bin_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Time-bin Analysis — summary.bin_analysis","title":"Summary Method for Time-bin Analysis — summary.bin_analysis","text":"Summary Method Time-bin Analysis","code":""},{"path":"/reference/summary.bin_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Time-bin Analysis — summary.bin_analysis","text":"","code":"# S3 method for bin_analysis summary(object, ...)"},{"path":"/reference/summary.bin_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Time-bin Analysis — summary.bin_analysis","text":"object output analyze_time_bins function ... Ignored","code":""},{"path":"/reference/summary.bin_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Time-bin Analysis — summary.bin_analysis","text":"Prints information run statistically significant time-bins, separately   positive negative","code":""},{"path":"/reference/summary.boot_splines_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Bootstrapped Splines Analysis — summary.boot_splines_analysis","title":"Summary Method for Bootstrapped Splines Analysis — summary.boot_splines_analysis","text":"Summary Method Bootstrapped Splines Analysis","code":""},{"path":"/reference/summary.boot_splines_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Bootstrapped Splines Analysis — summary.boot_splines_analysis","text":"","code":"# S3 method for boot_splines_analysis summary(object, ...)"},{"path":"/reference/summary.boot_splines_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Bootstrapped Splines Analysis — summary.boot_splines_analysis","text":"object output boot_splines_data function ... Ignored","code":""},{"path":"/reference/summary.boot_splines_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Bootstrapped Splines Analysis — summary.boot_splines_analysis","text":"Prints list divergence-times.","code":""},{"path":"/reference/summary.cluster_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Cluster Analysis — summary.cluster_analysis","title":"Summary Method for Cluster Analysis — summary.cluster_analysis","text":"Summary Method Cluster Analysis","code":""},{"path":"/reference/summary.cluster_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Cluster Analysis — summary.cluster_analysis","text":"","code":"# S3 method for cluster_analysis summary(object, ...)"},{"path":"/reference/summary.cluster_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Cluster Analysis — summary.cluster_analysis","text":"object output analyze_clusters function ... Ignored","code":""},{"path":"/reference/summary.cluster_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Cluster Analysis — summary.cluster_analysis","text":"Prints information bootstrapped null distribution, well information cluster.","code":""},{"path":"/reference/summary.time_cluster_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Method for Cluster Analysis — summary.time_cluster_data","title":"Summary Method for Cluster Analysis — summary.time_cluster_data","text":"Summary Method Cluster Analysis","code":""},{"path":"/reference/summary.time_cluster_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Method for Cluster Analysis — summary.time_cluster_data","text":"","code":"# S3 method for time_cluster_data summary(object, ...)"},{"path":"/reference/summary.time_cluster_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Method for Cluster Analysis — summary.time_cluster_data","text":"object output analyze_clusters function ... Ignored","code":""},{"path":"/reference/summary.time_cluster_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Method for Cluster Analysis — summary.time_cluster_data","text":"Prints information bootstrapped null distribution, well information cluster.","code":""},{"path":"/reference/trackloss_analysis.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze trackloss. — trackloss_analysis","title":"Analyze trackloss. — trackloss_analysis","text":"Get information trackloss data.","code":""},{"path":"/reference/trackloss_analysis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze trackloss. — trackloss_analysis","text":"","code":"trackloss_analysis(data)"},{"path":"/reference/trackloss_analysis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze trackloss. — trackloss_analysis","text":"data output make_eyetrackingr_data","code":""},{"path":"/reference/trackloss_analysis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze trackloss. — trackloss_analysis","text":"dataframe describing trackloss -trial -participant","code":""},{"path":"/reference/trackloss_analysis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze trackloss. — trackloss_analysis","text":"","code":"data(word_recognition) data <- make_eyetrackingr_data(word_recognition,                                 participant_column = \"ParticipantName\",                                trial_column = \"Trial\",                                time_column = \"TimeFromTrialOnset\",                                trackloss_column = \"TrackLoss\",                                aoi_columns = c('Animate','Inanimate'),                                treat_non_aoi_looks_as_missing = TRUE )  tl_analysis <- trackloss_analysis(data)"},{"path":"/reference/word_recognition.html","id":null,"dir":"Reference","previous_headings":"","what":"Data collected in an infant eyetracking study — word_recognition","title":"Data collected in an infant eyetracking study — word_recognition","text":"Data simple 2-alternative forced choice (2AFC) word recognition task administered 19-  24-month-olds. trial, infants shown picture animate object (e.g.,  horse) inanimate object (e.g., spoon). inspecting images, disappeared heard label referring one (e.g., \"horse nearby!\"). Finally, objects  re-appeared screen prompted look target (e.g., \"Look  horse!\").","code":""},{"path":"/reference/word_recognition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data collected in an infant eyetracking study — word_recognition","text":"","code":"word_recognition"},{"path":"/reference/word_recognition.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data collected in an infant eyetracking study — word_recognition","text":"data frame 53940 rows 10 variables: ParticipantName Uniaue    participant ID Sex M F Age Age, months TrialNum Unique Trial    Number Trial Name item shown trial (also unique participant) TimeFromTrialOnset Time within trial Subphase Subphase within trial (see ) TimeFromSubphaseOnset Time within subphase AOI AOI looking Animate looking animate AOI? Inanimate looking    inanimate AOI? TrackLoss current sample valid tracking data? MCDI_Total Total vocabulary score MCDI MCDI_Nouns Noun vocabulary score    MCDI MCDI_Verbs Verb vocabulary score MCDI","code":""},{"path":"/reference/word_recognition.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data collected in an infant eyetracking study — word_recognition","text":"Ferguson, B., Graf, E., & Waxman, S. R. (2014). Infants use known verbs learn novel   nouns: Evidence 15- 19-month-olds. Cognition, 131(1), 139-146.","code":""}]
